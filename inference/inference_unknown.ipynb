{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3989324/2109291646.py:13: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "/media/disk1/chatgpt/miniconda3/envs/self-rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    ")\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"2b219db0d2984f9dae28b651ab8ab3d9\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://smsh.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-03-01-preview\"\n",
    "# embeddings = AzureOpenAIEmbeddings(\n",
    "#     model=\"text-embedding-3-small\",\n",
    "# )\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "                # model_kwargs={'device': 'cpu'},\n",
    "                encode_kwargs={'normalize_embeddings': False},\n",
    "            )\n",
    "from langchain.storage import LocalFileStore, RedisStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "store = RedisStore(redis_url=\"redis://localhost:6379\")\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "embeddings, store, namespace=\"bge-large\"\n",
    ")\n",
    "row_string = []\n",
    "with open('./data/clean_relations', 'r') as f:\n",
    "    r_data = [line.strip() for line in f]\n",
    "all_db = FAISS.from_texts(r_data, cached_embedder)\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create with GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"2b219db0d2984f9dae28b651ab8ab3d9\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://smsh.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    temperature=1,\n",
    "    n = 3,\n",
    "    max_retries=5, request_timeout=600\n",
    ")\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3989324/3707533165.py:28: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=model, prompt=few_shot_intepretable_prompt, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "# The name of Justin Bieber's brother is Jaxon Bieber. This is based on the reasoning path that connects Justin Bieber to Jaxon Bieber through the relationship of sibling. The other paths that connect Justin Bieber to Jazmyn Bieber or back to Justin Bieber himself are incorrect in this context.\n",
    "few_shot_intepretable_prompt = FewShotPromptTemplate(\n",
    "        examples=[{\n",
    "            \"query\": \"Who was the prime minister of Japan in 2011, that served in the New Party Sakigake?\",\n",
    "            \"evidence\": \"Relations retrieved: language.human_language.countries_spoken_in\\n Entities retrieved: Japan\",\n",
    "            \"preceding_sentences\": \"\",\n",
    "            \"output\": \"Naoto Kan\",\n",
    "            \"rating\": \"[Continue to Retrieve Evidence]\"\n",
    "        }],\n",
    "        example_prompt=PromptTemplate.from_template(\"\"\"Query: {query}\n",
    "Preceding sentences: {preceding_sentences}\n",
    "Evidence: {evidence}\n",
    "Output: {target_output}\n",
    "Rating: {rating}\"\"\"),\n",
    "        prefix=\n",
    "        \"You will be provided with a query, evidence, output sentence, and preceding sentences (optional). Your task is to determine whether the information in the output sentence can be fully verified by the evidence or if it requires further external verification. There are three cases:\\n\" \n",
    "        \"- If the output sentence can be verified solely with the evidence and the preceding sentences, then respond with [No Retrieval]. \\n\"\n",
    "        \"- If additional information about the tail entity in evidence is needed to verify the output sentence, respond with [Continue to Retrieve Evidence] \\n\"\n",
    "        \"- If more information unrelated to the evidence is needed, e.g. totally new relationship or new entity, reponse with [New Retrieval].\\n\\n\",\n",
    "        suffix=\n",
    "        \"Query: {query}\\n\"\n",
    "        \"Preceding sentences: {preceding_sentences}\\n\"\n",
    "        \"Evidence: {evidence}\\n\"\n",
    "        \"Output: {target_output}\",\n",
    "        input_variables=[\"query\", \"evidence\", \"preceding_sentences\", \"topic\"],\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=model, prompt=few_shot_intepretable_prompt, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship relevance\n",
    "graph_intepretable =  \"\"\"You will receive a query, evidence and optional preceding sentences containing history information. The evidence contains graph relationships or entities may be useful to answer the query. Your task is to filters out valid information from the evidence to answer the given query, evaluate your output and provide explanations on your result.\n",
    "\n",
    "###\n",
    "Query: Name the president of the country whose main spoken language was Brahui in 1980?\n",
    "Topic Entity: Brahui Language\n",
    "Evidence: language.human_language.main_country; language.human_language.language_family; language.human_language.iso_639_3_code; base.rosetta.languoid.parent; language.human_language.writing_system; base.rosetta.languoid.languoid_class; language.human_language.countries_spoken_in; kg.object_profile.prominent_type; base.rosetta.languoid.document; base.ontologies.ontology_instance.equivalent_instances; base.rosetta.languoid.local_name; language.human_language.region\n",
    "Preceding sentences: \n",
    "Output: \n",
    "1. {{language.human_language.main_country (Score: Fully relavant))}}: This relation is highly relevant as it directly relates to the country whose president is being asked for, and the main country where Brahui language is spoken in 1980.\n",
    "2. {{language.human_language.countries_spoken_in (Score: Fully relavant)}}: This relation is also relevant as it provides information on the countries where Brahui language is spoken, which could help narrow down the search for the president.\n",
    "3. {{base.rosetta.languoid.parent (Score: Partially relevant)}}: This relation is less relevant but still provides some context on the language family to which Brahui belongs, which could be useful in understanding the linguistic and cultural background of the country in question.\n",
    "\n",
    "###\n",
    "Query: {query}\n",
    "Topic Entity: {topic}\n",
    "Evidence: {evidence}\n",
    "Preceding sentences: {preceding_sentences}\n",
    "Output: \n",
    "\"\"\"\n",
    "# The name of Justin Bieber's brother is Jaxon Bieber. This is based on the reasoning path that connects Justin Bieber to Jaxon Bieber through the relationship of sibling. The other paths that connect Justin Bieber to Jazmyn Bieber or back to Justin Bieber himself are incorrect in this context.\n",
    "few_shot_intepretable_prompt = FewShotPromptTemplate(\n",
    "        examples=[{\n",
    "            \"query\": \"Name the president of the country whose main spoken language was Brahui in 1980?\",\n",
    "            \"topic\": \"Brahui Language\",\n",
    "            \"evidence\": \"language.human_language.main_country; language.human_language.language_family; language.human_language.iso_639_3_code; base.rosetta.languoid.parent; language.human_language.writing_system; base.rosetta.languoid.languoid_class; language.human_language.countries_spoken_in; kg.object_profile.prominent_type; base.rosetta.languoid.document; base.ontologies.ontology_instance.equivalent_instances; base.rosetta.languoid.local_name; language.human_language.region\",\n",
    "            \"preceding_sentences\": \"\",\n",
    "            \"output\": \"\"\"1. {{language.human_language.main_country (Score: [Fully Relavant])}}: This relation is highly relevant as it directly relates to the country whose president is being asked for, and the main country where Brahui language is spoken in 1980.\n",
    "2. {{language.human_language.countries_spoken_in (Score: [Fully Relavant])}}: This relation is also relevant as it provides information on the countries where Brahui language is spoken, which could help narrow down the search for the president.\n",
    "3. {{base.rosetta.languoid.parent (Score: [Partially Relevant])}}: This relation is less relevant but still provides some context on the language family to which Brahui belongs, which could be useful in understanding the linguistic and cultural background of the country in question.\"\"\"\n",
    "        }],\n",
    "        example_prompt=PromptTemplate.from_template(\"\"\"###\n",
    "Query: {query}\n",
    "Topic Entity: {topic}\n",
    "Evidence: {evidence}\n",
    "Preceding sentences: {preceding_sentences}\n",
    "Output: {output}\n",
    "\"\"\"),\n",
    "        prefix=\n",
    "        \"\"\"You will receive a query, topic entity, evidence and optional preceding sentences containing history information. The evidence contains graph relationships or entities may be useful to answer the query. Your task is to filters out 3 valid information from the evidence that contribute to answering the query and provide a relevance score for each output, output your explanations for the score.\n",
    "The score of relevance range from [Fully Relavant], [Partially Relevant] to [Unrelevant].\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"###\n",
    "Query: {query}\n",
    "Topic Entity: {topic}\n",
    "Evidence: {evidence}\n",
    "Preceding sentences: {preceding_sentences}\n",
    "Output: \"\"\",\n",
    "        input_variables=[\"query\", \"evidence\", \"preceding_sentences\", \"topic\"],\n",
    ")\n",
    "graph_intepretable_prompt = PromptTemplate(input_variables=[\"query\", \"evidence\", \"preceding_sentences\", \"topic\"], template=\n",
    "graph_intepretable)\n",
    "llm_chain = LLMChain(llm=model, prompt=few_shot_intepretable_prompt, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "few_shot_intepretable_prompt = FewShotPromptTemplate(\n",
    "        examples=[{\n",
    "            \"query\": \"what is the name of justin bieber brother?\",\n",
    "            \"output\": \"[Retreive New Relationship]<paragraph>people.sibling_relationship.sibling;fictional_universe.fictional_character.siblings;fictional_universe.sibling_relationship_of_fictional_characters.siblings;people.person.sibling_s;people.family.members;people.person.parents</paragraph>Retrieved relationship: people.person.parents[Fully Relevant][Retrieve Entity]<paragraph>(Justin Bieber, people.person.parents, Pattie Mallette);(Justin Bieber, people.person.parents, Jeremy Bieber);(Justin Bieber, people.person.parents, Jeremy Bieber)</paragraph>Retrieved triplet: (Justin Bieber, people.person.parents, Jeremy Bieber)[Fully Relevant][Continue to Retrieve Evidence]<paragraph>people.sibling_relationship.sibling;people.person.sibling_s;people.person.parents;fictional_universe.fictional_character.siblings;people.family.members;people.person.children</paragraph>Retrieved relationship: people.person.children[Fully Relevant][Retrieve Entity]<paragraph>(Jeremy Bieber, people.person.children, Jazmyn Bieber);(Jeremy Bieber, people.person.children, Justin Bieber);(Jeremy Bieber, people.person.children, Jaxon Bieber);(Jeremy Bieber, people.person.children, Jaxon Bieber)</paragraph>Retrieved triplet: (Jeremy Bieber, people.person.children, Jaxon Bieber)[Fully Relevant][No Retrieval] Answer: Jaxon Bieber\",\n",
    "            \"explanation\": \"The output provides the name of justin bieber's brother. This is based on the reasoning path that connects Justin Bieber to Jaxon Bieber through the relationship of sibling. The other paths that connect Justin Bieber to Jazmyn Bieber or back to Justin Bieber himself are incorrect in this context.\",\n",
    "            \"rating\": \"[Confidence:5]\"\n",
    "        }],\n",
    "        example_prompt=PromptTemplate.from_template(\"\"\"\n",
    "Query: {query}\\n\n",
    "Output: {output}\n",
    "Explanation: {explanation}\n",
    "Rating: {rating}\n",
    "\"\"\"),\n",
    "        prefix=\"\"\"Given a query and an output, rate whether the response and the thought process appears to be a helpful and informative answer to the query, from 1 (lowest) - 5 (highest). We call this confidence score.\n",
    "[Confidence:5]: The response provides a complete and correct reasoning chain to the query, and the final answer is complete and logically correct.\n",
    "[Confidence:4]: The response mostly fulfills the need in the query and provides correct answers, while there can be some minor improvements such as shorter reasoning chain or less repetition.\n",
    "[Confidence:3]: The response is acceptable, but the answers may be not complete or needs minor improvement.\n",
    "[Confidence:2]: The reasoning process still addresses the main request, but the answers are not correct or not relevant to the query.\n",
    "[Confidence:1]: The reasoning is barely irrelevant or does not give an answer in the end.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "Query: {query}\\n\n",
    "Output: {output}\\n\"\"\",\n",
    "        input_variables=[\"query\", \"output\"],\n",
    ")\n",
    "# confidence_prompt = PromptTemplate(input_variables=[\"query\", \"output\"], template=\n",
    "# graph_intepretable)\n",
    "llm_chain = LLMChain(llm=model, prompt=few_shot_intepretable_prompt, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run_long_form answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-19 06:20:03 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 06:20:03,921\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-19 06:20:08 config.py:905] Defaulting to use mp for distributed inference\n",
      "INFO 12-19 06:20:08 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='/media/disk2/llama_factory/generation_1209_no_mask', speculative_config=None, tokenizer='/media/disk2/llama_factory/generation_1209_no_mask', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/media/disk2/llama_factory/generation_1209_no_mask, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "WARNING 12-19 06:20:09 multiproc_gpu_executor.py:127] CUDA was previously initialized. We must use the `spawn` multiprocessing start method. Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'.\n",
      "WARNING 12-19 06:20:09 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 12-19 06:20:09 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "WARNING 12-19 06:20:11 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.\n",
      "WARNING 12-19 06:20:11 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.\n",
      "WARNING 12-19 06:20:11 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m INFO 12-19 06:20:13 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:13 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:13 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 12-19 06:20:14 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "INFO 12-19 06:20:14 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:14 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:14 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "INFO 12-19 06:20:14 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:14 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:14 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m INFO 12-19 06:20:14 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "WARNING 12-19 06:20:15 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m WARNING 12-19 06:20:15 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m WARNING 12-19 06:20:15 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m WARNING 12-19 06:20:15 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 12-19 06:20:15 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f9665e116f0>, local_subscribe_port=49899, remote_subscribe_port=None)\n",
      "INFO 12-19 06:20:15 model_runner.py:1056] Starting to load model /media/disk2/llama_factory/generation_1209_no_mask...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:15 model_runner.py:1056] Starting to load model /media/disk2/llama_factory/generation_1209_no_mask...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:15 model_runner.py:1056] Starting to load model /media/disk2/llama_factory/generation_1209_no_mask...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m INFO 12-19 06:20:15 model_runner.py:1056] Starting to load model /media/disk2/llama_factory/generation_1209_no_mask...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  3.59it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.60it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.90it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.13it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.06it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:17 model_runner.py:1067] Loading model weights took 3.7420 GB\n",
      "INFO 12-19 06:20:17 model_runner.py:1067] Loading model weights took 3.7420 GB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:17 model_runner.py:1067] Loading model weights took 3.7420 GB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m INFO 12-19 06:20:17 model_runner.py:1067] Loading model weights took 3.7420 GB\n",
      "INFO 12-19 06:20:20 distributed_gpu_executor.py:57] # GPU blocks: 61347, # CPU blocks: 8192\n",
      "INFO 12-19 06:20:20 distributed_gpu_executor.py:61] Maximum concurrency for 8192 tokens per request: 119.82x\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m INFO 12-19 06:20:22 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m INFO 12-19 06:20:22 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-19 06:20:22 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-19 06:20:22 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:22 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:22 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:22 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:22 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047129)\u001b[0;0m INFO 12-19 06:20:38 model_runner.py:1523] Graph capturing finished in 16 secs.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047128)\u001b[0;0m INFO 12-19 06:20:38 model_runner.py:1523] Graph capturing finished in 16 secs.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=4047130)\u001b[0;0m INFO 12-19 06:20:38 model_runner.py:1523] Graph capturing finished in 17 secs.\n",
      "INFO 12-19 06:20:38 model_runner.py:1523] Graph capturing finished in 17 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "# model = LLM(model='/media/disk2/llama_factory/generation_1124_special', trust_remote_code=True, tensor_parallel_size=4)\n",
    "model = LLM(model='/media/disk2/llama_factory/generation_1209_no_mask', trust_remote_code=True, tensor_parallel_size=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, est. speed input: 16.91 toks/s, output: 99.50 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletionOutput(index=0, text='business[Partially Relevant]organization.organization_founder.organizations_founded;organization.organization.founders;organization.organization_membership.organization;organization.leadership.organization;business.sponsorship.sponsored_by</paragraph>organization.organization_membership.organization[Fully Relevant]organization.organization_founder.organizations_founded[Partially Relevant]organization.leadership.organization[Partially Relevant][Retrieve Entity]<paragraph>(Google, organization.organization.founders, Sergey Brin);(Google, organization.organization.founders, Larry Page)</paragraph>Sergey Brin[Partially Relevant]Larry Page[Partially Relevant][Continue to Retrieve Evidence]<paragraph>people.person.profession;', token_ids=(27243, 128262, 24844, 70324, 22200, 261, 51272, 8200, 766, 13382, 26, 24844, 70324, 840, 801, 388, 26, 24844, 70324, 85735, 70324, 26, 24844, 31602, 6527, 2200, 70324, 26, 27243, 516, 31341, 5383, 516, 35841, 3795, 128264, 24844, 70324, 85735, 70324, 128261, 24844, 70324, 22200, 261, 51272, 8200, 766, 13382, 128262, 24844, 31602, 6527, 2200, 70324, 128262, 128259, 128263, 6838, 2738, 11, 7471, 70324, 840, 801, 388, 11, 74529, 3320, 258, 1237, 7, 14783, 11, 7471, 70324, 840, 801, 388, 11, 30390, 5874, 8, 128264, 50, 10286, 88, 3320, 258, 128262, 89595, 5874, 128262, 128258, 128263, 16455, 31970, 93605, 1362, 26), cumulative_logprob=-0.6931509971545893, logprobs=[{27243: Logprob(logprob=0.0, rank=1, decoded_token='business'), 128259: Logprob(logprob=-24.9755859375, rank=2, decoded_token='[Retrieve Entity]'), 2588: Logprob(logprob=-162.3414306640625, rank=3, decoded_token='location'), 11789: Logprob(logprob=-181.0731201171875, rank=4, decoded_token='language'), 128256: Logprob(logprob=-199.8048095703125, rank=5, decoded_token='[No Retrieval]')}, {128262: Logprob(logprob=0.0, rank=1, decoded_token='[Partially Relevant]'), 128264: Logprob(logprob=-99.9024658203125, rank=2, decoded_token='</paragraph>'), 128260: Logprob(logprob=-106.1463623046875, rank=3, decoded_token='[Unrelevant]'), 26: Logprob(logprob=-131.1219482421875, rank=4, decoded_token=';'), 288: Logprob(logprob=-206.0487060546875, rank=5, decoded_token='es')}, {24844: Logprob(logprob=0.0, rank=1, decoded_token='organization'), 20510: Logprob(logprob=-237.268310546875, rank=2, decoded_token='law'), 2588: Logprob(logprob=-256.0, rank=3, decoded_token='location'), 128259: Logprob(logprob=-287.219482421875, rank=4, decoded_token='[Retrieve Entity]'), 86843: Logprob(logprob=-305.951171875, rank=5, decoded_token='internet')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 128262: Logprob(logprob=-87.4146728515625, rank=2, decoded_token='[Partially Relevant]'), 31602: Logprob(logprob=-168.58544921875, rank=3, decoded_token='.le'), 128260: Logprob(logprob=-212.292724609375, rank=4, decoded_token='[Unrelevant]'), 128261: Logprob(logprob=-249.756103515625, rank=5, decoded_token='[Fully Relevant]')}, {22200: Logprob(logprob=0.0, rank=1, decoded_token='_found'), 840: Logprob(logprob=-237.268310546875, rank=2, decoded_token='.f'), 49065: Logprob(logprob=-287.219482421875, rank=3, decoded_token='_spin'), 85735: Logprob(logprob=-324.682861328125, rank=4, decoded_token='_membership'), 31602: Logprob(logprob=-362.1463623046875, rank=5, decoded_token='.le')}, {261: Logprob(logprob=0.0, rank=1, decoded_token='er'), 388: Logprob(logprob=-1311.219482421875, rank=2, decoded_token='ers'), 287: Logprob(logprob=-1448.5853271484375, rank=3, decoded_token='ing'), 1697: Logprob(logprob=-1748.2926025390625, rank=4, decoded_token='ational'), 977: Logprob(logprob=-1823.219482421875, rank=5, decoded_token='ater')}, {51272: Logprob(logprob=0.0, rank=1, decoded_token='.organ'), 13: Logprob(logprob=-824.1951904296875, rank=2, decoded_token='.'), 70324: Logprob(logprob=-967.804931640625, rank=3, decoded_token='.organization'), 70353: Logprob(logprob=-1061.4635009765625, rank=4, decoded_token='organizations'), 2726: Logprob(logprob=-1061.4635009765625, rank=5, decoded_token='.org')}, {8200: Logprob(logprob=0.0, rank=1, decoded_token='izations'), 56276: Logprob(logprob=-1298.7318115234375, rank=2, decoded_token='isations'), 12509: Logprob(logprob=-1361.1707763671875, rank=3, decoded_token='izers'), 77491: Logprob(logprob=-1386.146484375, rank=4, decoded_token='izational'), 3213: Logprob(logprob=-1386.146484375, rank=5, decoded_token='izer')}, {766: Logprob(logprob=0.0, rank=1, decoded_token='_f'), 840: Logprob(logprob=-1111.41455078125, rank=2, decoded_token='.f'), 78811: Logprob(logprob=-1148.8780517578125, rank=3, decoded_token=' Founded'), 1426: Logprob(logprob=-1198.8292236328125, rank=4, decoded_token='_F'), 8074: Logprob(logprob=-1236.2926025390625, rank=5, decoded_token='_form')}, {13382: Logprob(logprob=0.0, rank=1, decoded_token='ounded'), 13900: Logprob(logprob=-1361.170654296875, rank=2, decoded_token='ounding'), 3171: Logprob(logprob=-1648.39013671875, rank=3, decoded_token='ounds'), 37153: Logprob(logprob=-1723.3170166015625, rank=4, decoded_token='unded'), 801: Logprob(logprob=-1723.3170166015625, rank=5, decoded_token='ound')}, {26: Logprob(logprob=0.0, rank=1, decoded_token=';'), 82960: Logprob(logprob=-649.3658447265625, rank=2, decoded_token=';base'), 128264: Logprob(logprob=-699.3170166015625, rank=3, decoded_token='</paragraph>'), 40514: Logprob(logprob=-936.5853271484375, rank=4, decoded_token=';s'), 128262: Logprob(logprob=-1061.46337890625, rank=5, decoded_token='[Partially Relevant]')}, {24844: Logprob(logprob=0.0, rank=1, decoded_token='organization'), 27243: Logprob(logprob=-387.121826171875, rank=2, decoded_token='business'), 20510: Logprob(logprob=-524.48779296875, rank=3, decoded_token='law'), 86843: Logprob(logprob=-724.2926025390625, rank=4, decoded_token='internet'), 2239: Logprob(logprob=-761.7559814453125, rank=5, decoded_token='book')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 31602: Logprob(logprob=-636.878173828125, rank=2, decoded_token='.le'), 24844: Logprob(logprob=-1148.8780517578125, rank=3, decoded_token='organization'), 51272: Logprob(logprob=-1186.341552734375, rank=4, decoded_token='.organ'), 83452: Logprob(logprob=-1255.0244140625, rank=5, decoded_token='_organization')}, {840: Logprob(logprob=0.0, rank=1, decoded_token='.f'), 85735: Logprob(logprob=-449.5609130859375, rank=2, decoded_token='_membership'), 10108: Logprob(logprob=-524.48779296875, rank=3, decoded_token='.date'), 49065: Logprob(logprob=-574.43896484375, rank=4, decoded_token='_spin'), 22200: Logprob(logprob=-780.48779296875, rank=5, decoded_token='_found')}, {801: Logprob(logprob=0.0, rank=1, decoded_token='ound'), 13900: Logprob(logprob=-1386.146240234375, rank=2, decoded_token='ounding'), 13382: Logprob(logprob=-1423.6097412109375, rank=3, decoded_token='ounded'), 13891: Logprob(logprob=-1548.48779296875, rank=4, decoded_token='OUND'), 21846: Logprob(logprob=-1735.8048095703125, rank=5, decoded_token='actors')}, {388: Logprob(logprob=0.0, rank=1, decoded_token='ers'), 4419: Logprob(logprob=-1498.5364990234375, rank=2, decoded_token='ERS'), 56090: Logprob(logprob=-1760.7803955078125, rank=3, decoded_token='ersh'), 5544: Logprob(logprob=-1860.682861328125, rank=4, decoded_token='rs'), 4257: Logprob(logprob=-1910.6341552734375, rank=5, decoded_token='_date')}, {26: Logprob(logprob=0.0, rank=1, decoded_token=';'), 82960: Logprob(logprob=-599.41455078125, rank=2, decoded_token=';base'), 40514: Logprob(logprob=-961.5609130859375, rank=3, decoded_token=';s'), 128264: Logprob(logprob=-1236.2926025390625, rank=4, decoded_token='</paragraph>'), 79732: Logprob(logprob=-1311.219482421875, rank=5, decoded_token=';c')}, {24844: Logprob(logprob=0.0, rank=1, decoded_token='organization'), 27243: Logprob(logprob=-349.65869140625, rank=2, decoded_token='business'), 20510: Logprob(logprob=-349.65869140625, rank=3, decoded_token='law'), 86843: Logprob(logprob=-749.2684326171875, rank=4, decoded_token='internet'), 37838: Logprob(logprob=-774.2440185546875, rank=5, decoded_token='education')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 31602: Logprob(logprob=-462.048828125, rank=2, decoded_token='.le'), 24844: Logprob(logprob=-1148.8780517578125, rank=3, decoded_token='organization'), 83452: Logprob(logprob=-1223.8048095703125, rank=4, decoded_token='_organization'), 50983: Logprob(logprob=-1336.195068359375, rank=5, decoded_token='.non')}, {85735: Logprob(logprob=0.0, rank=1, decoded_token='_membership'), 10108: Logprob(logprob=-174.8291015625, rank=2, decoded_token='.date'), 49065: Logprob(logprob=-287.2193603515625, rank=3, decoded_token='_spin'), 25463: Logprob(logprob=-399.609619140625, rank=4, decoded_token='.place'), 26270: Logprob(logprob=-474.5364990234375, rank=5, decoded_token='.board')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 51272: Logprob(logprob=-1061.4635009765625, rank=2, decoded_token='.organ'), 27097: Logprob(logprob=-1086.4390869140625, rank=3, decoded_token='.role'), 24844: Logprob(logprob=-1117.65869140625, rank=4, decoded_token='organization'), 45939: Logprob(logprob=-1123.902587890625, rank=5, decoded_token='.members')}, {26: Logprob(logprob=0.0, rank=1, decoded_token=';'), 82960: Logprob(logprob=-586.9267578125, rank=2, decoded_token=';base'), 40514: Logprob(logprob=-699.317138671875, rank=3, decoded_token=';s'), 128264: Logprob(logprob=-1186.3414306640625, rank=4, decoded_token='</paragraph>'), 56033: Logprob(logprob=-1236.2926025390625, rank=5, decoded_token=';b')}, {24844: Logprob(logprob=0.0, rank=1, decoded_token='organization'), 27243: Logprob(logprob=-199.8046875, rank=2, decoded_token='business'), 20510: Logprob(logprob=-586.9267578125, rank=3, decoded_token='law'), 86843: Logprob(logprob=-649.36572265625, rank=4, decoded_token='internet'), 37838: Logprob(logprob=-799.2193603515625, rank=5, decoded_token='education')}, {31602: Logprob(logprob=0.0, rank=1, decoded_token='.le'), 70324: Logprob(logprob=-62.43896484375, rank=2, decoded_token='.organization'), 24844: Logprob(logprob=-855.41455078125, rank=3, decoded_token='organization'), 12013: Logprob(logprob=-899.121826171875, rank=4, decoded_token='_le'), 51272: Logprob(logprob=-1017.7559814453125, rank=5, decoded_token='.organ')}, {6527: Logprob(logprob=0.0, rank=1, decoded_token='aders'), 1013: Logprob(logprob=-1748.292724609375, rank=2, decoded_token='ader'), 13572: Logprob(logprob=-2659.902587890625, rank=3, decoded_token='iders'), 10798: Logprob(logprob=-2697.365966796875, rank=4, decoded_token='ADER'), 2277: Logprob(logprob=-2747.3173828125, rank=5, decoded_token='ading')}, {2200: Logprob(logprob=0.0, rank=1, decoded_token='hip'), 69154: Logprob(logprob=-1536.0, rank=2, decoded_token='HIP'), 6151: Logprob(logprob=-1710.829345703125, rank=3, decoded_token='hi'), 5383: Logprob(logprob=-1910.63427734375, rank=4, decoded_token='ship'), 34322: Logprob(logprob=-2135.41455078125, rank=5, decoded_token='hips')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 24844: Logprob(logprob=-1111.41455078125, rank=2, decoded_token='organization'), 83452: Logprob(logprob=-1123.90234375, rank=3, decoded_token='_organization'), 2726: Logprob(logprob=-1136.39013671875, rank=4, decoded_token='.org'), 7471: Logprob(logprob=-1261.2681884765625, rank=5, decoded_token=' organization')}, {26: Logprob(logprob=0.0, rank=1, decoded_token=';'), 82960: Logprob(logprob=-399.60986328125, rank=2, decoded_token=';base'), 40514: Logprob(logprob=-586.9267578125, rank=3, decoded_token=';s'), 128264: Logprob(logprob=-1048.9755859375, rank=4, decoded_token='</paragraph>'), 56033: Logprob(logprob=-1073.9512939453125, rank=5, decoded_token=';b')}, {27243: Logprob(logprob=0.0, rank=1, decoded_token='business'), 24844: Logprob(logprob=-112.390380859375, rank=2, decoded_token='organization'), 86843: Logprob(logprob=-649.365966796875, rank=3, decoded_token='internet'), 20510: Logprob(logprob=-686.829345703125, rank=4, decoded_token='law'), 37838: Logprob(logprob=-774.2440185546875, rank=5, decoded_token='education')}, {516: Logprob(logprob=0.0, rank=1, decoded_token='.s'), 28020: Logprob(logprob=-212.2926025390625, rank=2, decoded_token='.company'), 83118: Logprob(logprob=-249.7559814453125, rank=3, decoded_token='.shopping'), 26270: Logprob(logprob=-374.634033203125, rank=4, decoded_token='.board'), 13: Logprob(logprob=-387.121826171875, rank=5, decoded_token='.')}, {31341: Logprob(logprob=0.0, rank=1, decoded_token='ponsor'), 35841: Logprob(logprob=-536.9755859375, rank=2, decoded_token='ponsored'), 2805: Logprob(logprob=-924.0975341796875, rank=3, decoded_token='pons'), 51976: Logprob(logprob=-1011.5120849609375, rank=4, decoded_token='ponsors'), 621: Logprob(logprob=-1136.39013671875, rank=5, decoded_token='pon')}, {5383: Logprob(logprob=0.0, rank=1, decoded_token='ship'), 18143: Logprob(logprob=-1198.829345703125, rank=2, decoded_token='ships'), 2200: Logprob(logprob=-1311.2196044921875, rank=3, decoded_token='hip'), 71320: Logprob(logprob=-1454.829345703125, rank=4, decoded_token='SHIP'), 70131: Logprob(logprob=-1673.365966796875, rank=5, decoded_token='_relationship')}, {516: Logprob(logprob=0.0, rank=1, decoded_token='.s'), 11448: Logprob(logprob=-1092.6829833984375, rank=2, decoded_token='.rec'), 6064: Logprob(logprob=-1105.1707763671875, rank=3, decoded_token='.aw'), 70324: Logprob(logprob=-1130.1463623046875, rank=4, decoded_token='.organization'), 646: Logprob(logprob=-1148.8780517578125, rank=5, decoded_token='_s')}, {35841: Logprob(logprob=0.0, rank=1, decoded_token='ponsored'), 31341: Logprob(logprob=-1148.878173828125, rank=2, decoded_token='ponsor'), 74847: Logprob(logprob=-1248.780517578125, rank=3, decoded_token=' Sponsored'), 30638: Logprob(logprob=-1323.7073974609375, rank=4, decoded_token=' sponsored'), 1042: Logprob(logprob=-1598.4390869140625, rank=5, decoded_token='ponse')}, {3795: Logprob(logprob=0.0, rank=1, decoded_token='_by'), 1729: Logprob(logprob=-1273.756103515625, rank=2, decoded_token='by'), 14656: Logprob(logprob=-1286.243896484375, rank=3, decoded_token='-by'), 7225: Logprob(logprob=-1336.195068359375, rank=4, decoded_token='_rec'), 1383: Logprob(logprob=-1461.0731201171875, rank=5, decoded_token='By')}, {128264: Logprob(logprob=0.0, rank=1, decoded_token='</paragraph>'), 26: Logprob(logprob=-399.609619140625, rank=2, decoded_token=';'), 83452: Logprob(logprob=-1048.9755859375, rank=3, decoded_token='_organization'), 70324: Logprob(logprob=-1048.9755859375, rank=4, decoded_token='.organization'), 128262: Logprob(logprob=-1161.36572265625, rank=5, decoded_token='[Partially Relevant]')}, {24844: Logprob(logprob=0.0, rank=1, decoded_token='organization'), 27243: Logprob(logprob=-287.219482421875, rank=2, decoded_token='business'), 128259: Logprob(logprob=-611.90234375, rank=3, decoded_token='[Retrieve Entity]'), 2588: Logprob(logprob=-936.5853271484375, rank=4, decoded_token='location'), 14783: Logprob(logprob=-992.7803955078125, rank=5, decoded_token='Google')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 31602: Logprob(logprob=-262.243896484375, rank=2, decoded_token='.le'), 24844: Logprob(logprob=-911.6097412109375, rank=3, decoded_token='organization'), 51272: Logprob(logprob=-924.09765625, rank=4, decoded_token='.organ'), 83452: Logprob(logprob=-980.292724609375, rank=5, decoded_token='_organization')}, {85735: Logprob(logprob=-3.814689989667386e-06, rank=1, decoded_token='_membership'), 22200: Logprob(logprob=-12.487796783447266, rank=2, decoded_token='_found'), 45939: Logprob(logprob=-337.170654296875, rank=3, decoded_token='.members'), 840: Logprob(logprob=-349.658447265625, rank=4, decoded_token='.f'), 31602: Logprob(logprob=-374.634033203125, rank=5, decoded_token='.le')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 7471: Logprob(logprob=-1198.829345703125, rank=2, decoded_token=' organization'), 24844: Logprob(logprob=-1236.292724609375, rank=3, decoded_token='organization'), 83452: Logprob(logprob=-1273.7562255859375, rank=4, decoded_token='_organization'), 51272: Logprob(logprob=-1411.1220703125, rank=5, decoded_token='.organ')}, {128261: Logprob(logprob=0.0, rank=1, decoded_token='[Fully Relevant]'), 128262: Logprob(logprob=-62.43896484375, rank=2, decoded_token='[Partially Relevant]'), 128260: Logprob(logprob=-649.3658447265625, rank=3, decoded_token='[Unrelevant]'), 58: Logprob(logprob=-1198.8292236328125, rank=4, decoded_token='['), 11: Logprob(logprob=-1317.46337890625, rank=5, decoded_token=',')}, {24844: Logprob(logprob=0.0, rank=1, decoded_token='organization'), 27243: Logprob(logprob=-262.243896484375, rank=2, decoded_token='business'), 8629: Logprob(logprob=-1005.268310546875, rank=3, decoded_token='organ'), 128259: Logprob(logprob=-1030.243896484375, rank=4, decoded_token='[Retrieve Entity]'), 1813: Logprob(logprob=-1030.243896484375, rank=5, decoded_token='org')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 31602: Logprob(logprob=-74.9267578125, rank=2, decoded_token='.le'), 24844: Logprob(logprob=-811.7073974609375, rank=3, decoded_token='organization'), 51272: Logprob(logprob=-836.6829833984375, rank=4, decoded_token='.organ'), 7471: Logprob(logprob=-974.048828125, rank=5, decoded_token=' organization')}, {22200: Logprob(logprob=0.0, rank=1, decoded_token='_found'), 31602: Logprob(logprob=-262.243896484375, rank=2, decoded_token='.le'), 840: Logprob(logprob=-387.1220703125, rank=3, decoded_token='.f'), 12013: Logprob(logprob=-636.8780517578125, rank=4, decoded_token='_le'), 766: Logprob(logprob=-905.365966796875, rank=5, decoded_token='_f')}, {261: Logprob(logprob=0.0, rank=1, decoded_token='er'), 388: Logprob(logprob=-1511.0244140625, rank=2, decoded_token='ers'), 38149: Logprob(logprob=-1573.4635009765625, rank=3, decoded_token='rer'), 643: Logprob(logprob=-1810.731689453125, rank=4, decoded_token='ER'), 81: Logprob(logprob=-1810.731689453125, rank=5, decoded_token='r')}, {51272: Logprob(logprob=0.0, rank=1, decoded_token='.organ'), 70324: Logprob(logprob=-1486.0487060546875, rank=2, decoded_token='.organization'), 8609: Logprob(logprob=-1648.39013671875, rank=3, decoded_token='rgan'), 8629: Logprob(logprob=-1673.36572265625, rank=4, decoded_token='organ'), 2726: Logprob(logprob=-1760.7803955078125, rank=5, decoded_token='.org')}, {8200: Logprob(logprob=0.0, rank=1, decoded_token='izations'), 56276: Logprob(logprob=-1685.8536376953125, rank=2, decoded_token='isations'), 13978: Logprob(logprob=-1710.8292236328125, rank=3, decoded_token='isms'), 70353: Logprob(logprob=-1848.195068359375, rank=4, decoded_token='organizations'), 811: Logprob(logprob=-1910.6341552734375, rank=5, decoded_token='ations')}, {766: Logprob(logprob=0.0, rank=1, decoded_token='_f'), 840: Logprob(logprob=-1398.63427734375, rank=2, decoded_token='.f'), 22200: Logprob(logprob=-1473.56103515625, rank=3, decoded_token='_found'), 1426: Logprob(logprob=-1692.09765625, rank=4, decoded_token='_F'), 18538: Logprob(logprob=-1729.56103515625, rank=5, decoded_token=' founded')}, {13382: Logprob(logprob=0.0, rank=1, decoded_token='ounded'), 13900: Logprob(logprob=-1723.3170166015625, rank=2, decoded_token='ounding'), 37153: Logprob(logprob=-1785.7559814453125, rank=3, decoded_token='unded'), 4159: Logprob(logprob=-1848.195068359375, rank=4, decoded_token='oundation'), 3023: Logprob(logprob=-1873.170654296875, rank=5, decoded_token='oud')}, {128262: Logprob(logprob=0.0, rank=1, decoded_token='[Partially Relevant]'), 128261: Logprob(logprob=-586.927001953125, rank=2, decoded_token='[Fully Relevant]'), 128260: Logprob(logprob=-886.63427734375, rank=3, decoded_token='[Unrelevant]'), 58: Logprob(logprob=-1323.7073974609375, rank=4, decoded_token='['), 11: Logprob(logprob=-1517.2684326171875, rank=5, decoded_token=',')}, {24844: Logprob(logprob=-0.6931471824645996, rank=2, decoded_token='organization'), 27243: Logprob(logprob=-0.6931471824645996, rank=1, decoded_token='business'), 79486: Logprob(logprob=-737.4736938476562, rank=3, decoded_token='leaders'), 128259: Logprob(logprob=-749.9614868164062, rank=4, decoded_token='[Retrieve Entity]'), 2588: Logprob(logprob=-812.4004516601562, rank=5, decoded_token='location')}, {31602: Logprob(logprob=0.0, rank=1, decoded_token='.le'), 70324: Logprob(logprob=-936.58544921875, rank=2, decoded_token='.organization'), 12013: Logprob(logprob=-1198.829345703125, rank=3, decoded_token='_le'), 51272: Logprob(logprob=-1492.292724609375, rank=4, decoded_token='.organ'), 75924: Logprob(logprob=-1498.53662109375, rank=5, decoded_token='(le')}, {6527: Logprob(logprob=0.0, rank=1, decoded_token='aders'), 1013: Logprob(logprob=-1923.1219482421875, rank=2, decoded_token='ader'), 7819: Logprob(logprob=-1998.048828125, rank=3, decoded_token='ads'), 13572: Logprob(logprob=-2085.46337890625, rank=4, decoded_token='iders'), 300: Logprob(logprob=-2254.048828125, rank=5, decoded_token='as')}, {2200: Logprob(logprob=0.0, rank=1, decoded_token='hip'), 5383: Logprob(logprob=-1598.43896484375, rank=2, decoded_token='ship'), 69154: Logprob(logprob=-1698.34130859375, rank=3, decoded_token='HIP'), 6151: Logprob(logprob=-1998.0487060546875, rank=4, decoded_token='hi'), 34322: Logprob(logprob=-2060.48779296875, rank=5, decoded_token='hips')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 83452: Logprob(logprob=-1161.36572265625, rank=2, decoded_token='_organization'), 7471: Logprob(logprob=-1211.3170166015625, rank=3, decoded_token=' organization'), 24844: Logprob(logprob=-1223.8048095703125, rank=4, decoded_token='organization'), 51272: Logprob(logprob=-1411.121826171875, rank=5, decoded_token='.organ')}, {128262: Logprob(logprob=0.0, rank=1, decoded_token='[Partially Relevant]'), 128260: Logprob(logprob=-274.731689453125, rank=2, decoded_token='[Unrelevant]'), 128261: Logprob(logprob=-949.0731201171875, rank=3, decoded_token='[Fully Relevant]'), 58: Logprob(logprob=-1136.39013671875, rank=4, decoded_token='['), 128259: Logprob(logprob=-1486.0487060546875, rank=5, decoded_token='[Retrieve Entity]')}, {128259: Logprob(logprob=0.0, rank=1, decoded_token='[Retrieve Entity]'), 27243: Logprob(logprob=-1386.1463623046875, rank=2, decoded_token='business'), 76: Logprob(logprob=-1767.0244140625, rank=3, decoded_token='m'), 24844: Logprob(logprob=-1816.9757080078125, rank=4, decoded_token='organization'), 3231: Logprob(logprob=-1829.4635009765625, rank=5, decoded_token='base')}, {128263: Logprob(logprob=0.0, rank=1, decoded_token='<paragraph>'), 10789: Logprob(logprob=-1860.6829833984375, rank=2, decoded_token='king'), 287: Logprob(logprob=-1973.0731201171875, rank=3, decoded_token='ing'), 128256: Logprob(logprob=-1991.804931640625, rank=4, decoded_token='[No Retrieval]'), 953: Logprob(logprob=-2060.48779296875, rank=5, decoded_token='ix')}, {6838: Logprob(logprob=0.0, rank=1, decoded_token='(G'), 5063: Logprob(logprob=-1236.2926025390625, rank=2, decoded_token='(L'), 7: Logprob(logprob=-1261.268310546875, rank=3, decoded_token='('), 14783: Logprob(logprob=-1336.195068359375, rank=4, decoded_token='Google'), 91316: Logprob(logprob=-1348.682861328125, rank=5, decoded_token=' GOOGLE')}, {2738: Logprob(logprob=0.0, rank=1, decoded_token='oogle'), 46: Logprob(logprob=-1036.48779296875, rank=2, decoded_token='O'), 103062: Logprob(logprob=-1461.0731201171875, rank=3, decoded_token='oog'), 78: Logprob(logprob=-1473.5609130859375, rank=4, decoded_token='o'), 1786: Logprob(logprob=-1623.41455078125, rank=5, decoded_token='ool')}, {11: Logprob(logprob=0.0, rank=1, decoded_token=','), 4800: Logprob(logprob=-674.341552734375, rank=2, decoded_token=' Now'), 4953: Logprob(logprob=-699.317138671875, rank=3, decoded_token=' Inc'), 15620: Logprob(logprob=-699.317138671875, rank=4, decoded_token=' LLC'), 34120: Logprob(logprob=-861.6585693359375, rank=5, decoded_token=' Apps')}, {7471: Logprob(logprob=0.0, rank=1, decoded_token=' organization'), 4953: Logprob(logprob=-949.0732421875, rank=2, decoded_token=' Inc'), 24844: Logprob(logprob=-999.0244140625, rank=3, decoded_token='organization'), 70324: Logprob(logprob=-999.0244140625, rank=4, decoded_token='.organization'), 2626: Logprob(logprob=-1098.9268798828125, rank=5, decoded_token=' business')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 7471: Logprob(logprob=-1286.243896484375, rank=2, decoded_token=' organization'), 24844: Logprob(logprob=-1298.731689453125, rank=3, decoded_token='organization'), 83452: Logprob(logprob=-1323.7073974609375, rank=4, decoded_token='_organization'), 31602: Logprob(logprob=-1448.58544921875, rank=5, decoded_token='.le')}, {840: Logprob(logprob=0.0, rank=1, decoded_token='.f'), 22200: Logprob(logprob=-611.90234375, rank=2, decoded_token='_found'), 26270: Logprob(logprob=-1098.9267578125, rank=3, decoded_token='.board'), 85735: Logprob(logprob=-1311.219482421875, rank=4, decoded_token='_membership'), 766: Logprob(logprob=-1329.951171875, rank=5, decoded_token='_f')}, {801: Logprob(logprob=0.0, rank=1, decoded_token='ound'), 13900: Logprob(logprob=-1361.170654296875, rank=2, decoded_token='ounding'), 1263: Logprob(logprob=-1498.5364990234375, rank=3, decoded_token='und'), 3171: Logprob(logprob=-1598.43896484375, rank=4, decoded_token='ounds'), 13382: Logprob(logprob=-1610.9267578125, rank=5, decoded_token='ounded')}, {388: Logprob(logprob=0.0, rank=1, decoded_token='ers'), 5544: Logprob(logprob=-2060.48779296875, rank=2, decoded_token='rs'), 4419: Logprob(logprob=-2060.48779296875, rank=3, decoded_token='ERS'), 1105: Logprob(logprob=-2085.46337890625, rank=4, decoded_token='ors'), 56090: Logprob(logprob=-2435.1220703125, rank=5, decoded_token='ersh')}, {11: Logprob(logprob=0.0, rank=1, decoded_token=','), 8: Logprob(logprob=-1860.682861328125, rank=2, decoded_token=')'), 1174: Logprob(logprob=-1866.9267578125, rank=3, decoded_token=' ,'), 345: Logprob(logprob=-1885.658447265625, rank=4, decoded_token=',\\n'), 13: Logprob(logprob=-1885.658447265625, rank=5, decoded_token='.')}, {74529: Logprob(logprob=0.0, rank=1, decoded_token=' Sergey'), 30390: Logprob(logprob=-487.0242919921875, rank=2, decoded_token=' Larry'), 85098: Logprob(logprob=-874.146240234375, rank=3, decoded_token=' Sergei'), 5874: Logprob(logprob=-986.5364990234375, rank=4, decoded_token=' Page'), 5195: Logprob(logprob=-986.5364990234375, rank=5, decoded_token=' Google')}, {3320: Logprob(logprob=0.0, rank=1, decoded_token=' Br'), 5874: Logprob(logprob=-811.707275390625, rank=2, decoded_token=' Page'), 30444: Logprob(logprob=-980.292724609375, rank=3, decoded_token=' Bin'), 74529: Logprob(logprob=-999.0244140625, rank=4, decoded_token=' Sergey'), 6971: Logprob(logprob=-1186.3414306640625, rank=5, decoded_token='Br')}, {258: Logprob(logprob=0.0, rank=1, decoded_token='in'), 19479: Logprob(logprob=-1311.219482421875, rank=2, decoded_token='ин'), 1354: Logprob(logprob=-1342.43896484375, rank=3, decoded_token='ins'), 6258: Logprob(logprob=-1411.121826171875, rank=4, decoded_token='inn'), 3817: Logprob(logprob=-1517.2681884765625, rank=5, decoded_token='lin')}, {1237: Logprob(logprob=0.0, rank=1, decoded_token=');'), 8: Logprob(logprob=-1161.3658447265625, rank=2, decoded_token=')'), 1680: Logprob(logprob=-1473.56103515625, rank=3, decoded_token='):'), 323: Logprob(logprob=-1523.51220703125, rank=4, decoded_token=' and'), 4772: Logprob(logprob=-1536.0, rank=5, decoded_token=\"');\")}, {7: Logprob(logprob=0.0, rank=1, decoded_token='('), 14783: Logprob(logprob=-1998.0487060546875, rank=2, decoded_token='Google'), 320: Logprob(logprob=-2185.36572265625, rank=3, decoded_token=' ('), 6838: Logprob(logprob=-2247.8046875, rank=4, decoded_token='(G'), 1209: Logprob(logprob=-2247.8046875, rank=5, decoded_token='((')}, {14783: Logprob(logprob=0.0, rank=1, decoded_token='Google'), 17943: Logprob(logprob=-1598.43896484375, rank=2, decoded_token='google'), 48255: Logprob(logprob=-1785.756103515625, rank=3, decoded_token='_google'), 5195: Logprob(logprob=-1823.219482421875, rank=4, decoded_token=' Google'), 63745: Logprob(logprob=-1848.195068359375, rank=5, decoded_token='-google')}, {11: Logprob(logprob=0.0, rank=1, decoded_token=','), 34120: Logprob(logprob=-1211.3170166015625, rank=2, decoded_token=' Apps'), 28508: Logprob(logprob=-1373.658447265625, rank=3, decoded_token=' Maps'), 9289: Logprob(logprob=-1473.5609130859375, rank=4, decoded_token='plex'), 7694: Logprob(logprob=-1486.0487060546875, rank=5, decoded_token=' Search')}, {7471: Logprob(logprob=0.0, rank=1, decoded_token=' organization'), 24844: Logprob(logprob=-1223.804931640625, rank=2, decoded_token='organization'), 70324: Logprob(logprob=-1236.292724609375, rank=3, decoded_token='.organization'), 83452: Logprob(logprob=-1648.3902587890625, rank=4, decoded_token='_organization'), 22139: Logprob(logprob=-1660.8780517578125, rank=5, decoded_token=' organisation')}, {70324: Logprob(logprob=0.0, rank=1, decoded_token='.organization'), 7471: Logprob(logprob=-1223.804931640625, rank=2, decoded_token=' organization'), 83452: Logprob(logprob=-1236.292724609375, rank=3, decoded_token='_organization'), 24844: Logprob(logprob=-1248.780517578125, rank=4, decoded_token='organization'), 2726: Logprob(logprob=-1585.9512939453125, rank=5, decoded_token='.org')}, {840: Logprob(logprob=0.0, rank=1, decoded_token='.f'), 22200: Logprob(logprob=-1785.756103515625, rank=2, decoded_token='_found'), 48727: Logprob(logprob=-1810.731689453125, rank=3, decoded_token=' founders'), 968: Logprob(logprob=-1960.58544921875, rank=4, decoded_token='(f'), 17514: Logprob(logprob=-1973.0732421875, rank=5, decoded_token=',f')}, {801: Logprob(logprob=0.0, rank=1, decoded_token='ound'), 1263: Logprob(logprob=-1098.9267578125, rank=2, decoded_token='und'), 3171: Logprob(logprob=-1411.121826171875, rank=3, decoded_token='ounds'), 13382: Logprob(logprob=-1423.6097412109375, rank=4, decoded_token='ounded'), 3023: Logprob(logprob=-1423.6097412109375, rank=5, decoded_token='oud')}, {388: Logprob(logprob=0.0, rank=1, decoded_token='ers'), 1105: Logprob(logprob=-1723.3173828125, rank=2, decoded_token='ors'), 4419: Logprob(logprob=-1898.146484375, rank=3, decoded_token='ERS'), 5079: Logprob(logprob=-1998.049072265625, rank=4, decoded_token='ners'), 261: Logprob(logprob=-1998.049072265625, rank=5, decoded_token='er')}, {11: Logprob(logprob=0.0, rank=1, decoded_token=','), 13: Logprob(logprob=-1773.2684326171875, rank=2, decoded_token='.'), 2637: Logprob(logprob=-1948.09765625, rank=3, decoded_token='.,'), 31214: Logprob(logprob=-1966.829345703125, rank=4, decoded_token=',L'), 1174: Logprob(logprob=-2110.43896484375, rank=5, decoded_token=' ,')}, {30390: Logprob(logprob=0.0, rank=1, decoded_token=' Larry'), 28574: Logprob(logprob=-1023.9998779296875, rank=2, decoded_token=' Lawrence'), 89595: Logprob(logprob=-1173.8536376953125, rank=3, decoded_token='Larry'), 5874: Logprob(logprob=-1211.3170166015625, rank=4, decoded_token=' Page'), 29808: Logprob(logprob=-1286.243896484375, rank=5, decoded_token=' Jerry')}, {5874: Logprob(logprob=0.0, rank=1, decoded_token=' Page'), 2732: Logprob(logprob=-1398.6341552734375, rank=2, decoded_token='Page'), 87511: Logprob(logprob=-1411.1219482421875, rank=3, decoded_token=' Paige'), 2199: Logprob(logprob=-1473.56103515625, rank=4, decoded_token=' page'), 52640: Logprob(logprob=-1560.9757080078125, rank=5, decoded_token='_Page')}, {8: Logprob(logprob=0.0, rank=1, decoded_token=')'), 340: Logprob(logprob=-1298.7318115234375, rank=2, decoded_token=')\\n'), 1237: Logprob(logprob=-1404.878173828125, rank=3, decoded_token=');'), 595: Logprob(logprob=-1610.9268798828125, rank=4, decoded_token='))'), 60: Logprob(logprob=-1610.9268798828125, rank=5, decoded_token=']')}, {128264: Logprob(logprob=0.0, rank=1, decoded_token='</paragraph>'), 128262: Logprob(logprob=-1891.9024658203125, rank=2, decoded_token='[Partially Relevant]'), 650: Logprob(logprob=-1910.63427734375, rank=3, decoded_token=' V'), 128258: Logprob(logprob=-1954.341552734375, rank=4, decoded_token='[Continue to Retrieve Evidence]'), 128260: Logprob(logprob=-1985.56103515625, rank=5, decoded_token='[Unrelevant]')}, {50: Logprob(logprob=0.0, rank=1, decoded_token='S'), 14783: Logprob(logprob=-711.804931640625, rank=2, decoded_token='Google'), 74529: Logprob(logprob=-1024.0001220703125, rank=3, decoded_token=' Sergey'), 32845: Logprob(logprob=-1173.853759765625, rank=4, decoded_token='Ser'), 89595: Logprob(logprob=-1211.317138671875, rank=5, decoded_token='Larry')}, {10286: Logprob(logprob=0.0, rank=1, decoded_token='erge'), 2431: Logprob(logprob=-911.609619140625, rank=2, decoded_token='erg'), 1216: Logprob(logprob=-1123.90234375, rank=3, decoded_token='ey'), 43043: Logprob(logprob=-1273.7559814453125, rank=4, decoded_token='ergy'), 74529: Logprob(logprob=-1373.658447265625, rank=5, decoded_token=' Sergey')}, {88: Logprob(logprob=0.0, rank=1, decoded_token='y'), 72: Logprob(logprob=-1585.9510498046875, rank=2, decoded_token='i'), 73: Logprob(logprob=-1617.170654296875, rank=3, decoded_token='j'), 1065: Logprob(logprob=-1717.072998046875, rank=4, decoded_token='ys'), 85407: Logprob(logprob=-1785.7559814453125, rank=5, decoded_token='yb')}, {3320: Logprob(logprob=0.0, rank=1, decoded_token=' Br'), 6971: Logprob(logprob=-1398.6341552734375, rank=2, decoded_token='Br'), 30444: Logprob(logprob=-1473.5609130859375, rank=3, decoded_token=' Bin'), 1437: Logprob(logprob=-1560.9755859375, rank=4, decoded_token=' br'), 426: Logprob(logprob=-1560.9755859375, rank=5, decoded_token=' B')}, {258: Logprob(logprob=0.0, rank=1, decoded_token='in'), 318: Logprob(logprob=-1685.8536376953125, rank=2, decoded_token='im'), 41622: Logprob(logprob=-1698.341552734375, rank=3, decoded_token='inz'), 321: Logprob(logprob=-1760.780517578125, rank=4, decoded_token='il'), 485: Logprob(logprob=-1785.756103515625, rank=5, decoded_token='ind')}, {128262: Logprob(logprob=0.0, rank=1, decoded_token='[Partially Relevant]'), 128260: Logprob(logprob=-49.951171875, rank=2, decoded_token='[Unrelevant]'), 58: Logprob(logprob=-199.804931640625, rank=3, decoded_token='['), 128261: Logprob(logprob=-880.3902587890625, rank=4, decoded_token='[Fully Relevant]'), 323: Logprob(logprob=-936.58544921875, rank=5, decoded_token=' and')}, {89595: Logprob(logprob=0.0, rank=1, decoded_token='Larry'), 30390: Logprob(logprob=-949.0732421875, rank=2, decoded_token=' Larry'), 39166: Logprob(logprob=-1436.09765625, rank=3, decoded_token='Law'), 128258: Logprob(logprob=-1685.8536376953125, rank=4, decoded_token='[Continue to Retrieve Evidence]'), 43: Logprob(logprob=-1773.268310546875, rank=5, decoded_token='L')}, {5874: Logprob(logprob=0.0, rank=1, decoded_token=' Page'), 2199: Logprob(logprob=-1423.609619140625, rank=2, decoded_token=' page'), 2732: Logprob(logprob=-1648.39013671875, rank=3, decoded_token='Page'), 43455: Logprob(logprob=-1723.3170166015625, rank=4, decoded_token=' Pag'), 66539: Logprob(logprob=-1798.2437744140625, rank=5, decoded_token='\\tPage')}, {128262: Logprob(logprob=0.0, rank=1, decoded_token='[Partially Relevant]'), 58: Logprob(logprob=-936.58544921875, rank=2, decoded_token='['), 128260: Logprob(logprob=-974.048828125, rank=3, decoded_token='[Unrelevant]'), 128261: Logprob(logprob=-1223.804931640625, rank=4, decoded_token='[Fully Relevant]'), 128264: Logprob(logprob=-1873.1707763671875, rank=5, decoded_token='</paragraph>')}, {128258: Logprob(logprob=0.0, rank=1, decoded_token='[Continue to Retrieve Evidence]'), 128256: Logprob(logprob=-412.09765625, rank=2, decoded_token='[No Retrieval]'), 14783: Logprob(logprob=-899.1219482421875, rank=3, decoded_token='Google'), 128259: Logprob(logprob=-1117.6585693359375, rank=4, decoded_token='[Retrieve Entity]'), 24844: Logprob(logprob=-1123.9024658203125, rank=5, decoded_token='organization')}, {128263: Logprob(logprob=0.0, rank=1, decoded_token='<paragraph>'), 95805: Logprob(logprob=-2048.0, rank=2, decoded_token=' Cyril'), 128258: Logprob(logprob=-2129.170654296875, rank=3, decoded_token='[Continue to Retrieve Evidence]'), 99632: Logprob(logprob=-2160.39013671875, rank=4, decoded_token=' Ting'), 49988: Logprob(logprob=-2172.8779296875, rank=5, decoded_token='任')}, {16455: Logprob(logprob=0.0, rank=1, decoded_token='people'), 27243: Logprob(logprob=-462.0487060546875, rank=2, decoded_token='business'), 20510: Logprob(logprob=-474.5364990234375, rank=3, decoded_token='law'), 258: Logprob(logprob=-561.951171875, rank=4, decoded_token='in'), 32261: Logprob(logprob=-624.39013671875, rank=5, decoded_token='music')}, {31970: Logprob(logprob=0.0, rank=1, decoded_token='.person'), 49190: Logprob(logprob=-1261.268310546875, rank=2, decoded_token='.eth'), 2337: Logprob(logprob=-1261.268310546875, rank=3, decoded_token='.de'), 88230: Logprob(logprob=-1286.243896484375, rank=4, decoded_token='.performance'), 24309: Logprob(logprob=-1336.195068359375, rank=5, decoded_token='_person')}, {93605: Logprob(logprob=0.0, rank=1, decoded_token='.prof'), 1276: Logprob(logprob=-474.53662109375, rank=2, decoded_token='.n'), 13: Logprob(logprob=-661.8536376953125, rank=3, decoded_token='.'), 10265: Logprob(logprob=-749.268310546875, rank=4, decoded_token='.ed'), 73861: Logprob(logprob=-924.0975341796875, rank=5, decoded_token='.parents')}, {1362: Logprob(logprob=0.0, rank=1, decoded_token='ession'), 8719: Logprob(logprob=-1311.219482421875, rank=2, decoded_token='essions'), 16151: Logprob(logprob=-1523.5120849609375, rank=3, decoded_token='essional'), 57081: Logprob(logprob=-1623.41455078125, rank=4, decoded_token='esion'), 434: Logprob(logprob=-1760.7803955078125, rank=5, decoded_token='ess')}, {26: Logprob(logprob=0.0, rank=1, decoded_token=';'), 82960: Logprob(logprob=-249.755859375, rank=2, decoded_token=';base'), 40514: Logprob(logprob=-624.39013671875, rank=3, decoded_token=';s'), 68336: Logprob(logprob=-1073.9510498046875, rank=4, decoded_token=';m'), 56033: Logprob(logprob=-1105.170654296875, rank=5, decoded_token=';b')}], finish_reason=length, stop_reason=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#是否带special token 分开传入，用于检索和生成\n",
    "sampling_params = SamplingParams(\n",
    "            temperature=0.01, top_p=1.0,max_tokens=100, logprobs=5, skip_special_tokens=False, include_stop_str_in_output=True)\n",
    "PROMPT_DICT = {\"llama3\": '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n{input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>'}\n",
    "model.generate([PROMPT_DICT[\"llama3\"].format(input=\"what all does google now do?\")], sampling_params)[0].outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/media/disk2/llama_factory/generation_1124_special')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_special_tokens(tokenizer, use_grounding=False, use_utility=False):\n",
    "    rel_tokens = {}\n",
    "    for token in ['[Unrelevant]','[Partially Relevant]','[Fully Relevant]']:\n",
    "        rel_tokens[token] = tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "    # ut_tokens = None\n",
    "    # if use_utility is True:\n",
    "    #     ut_tokens = {}\n",
    "    #     for token in utility_tokens_names:\n",
    "    #         ut_tokens[token] = tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "    return rel_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_tokens = load_special_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from src.sparql_utils import *\n",
    "def run_step_generation_batch(model, prompt, topic_entity,new_retrieval, beam_width=3):\n",
    "    pattern = r'(.*?)\\[(.*?)\\]'\n",
    "    rel_score_dict = {}\n",
    "    return_entities = []\n",
    "    final_preds = []\n",
    "    overall_scores = {}\n",
    "    paragraph = ';'.join([page.page_content.strip() for page in retriever.invoke(prompt.split('\\n\\n')[1].split('<|eot_id|>')[0])])\n",
    "    print(paragraph)\n",
    "    if new_retrieval:\n",
    "        retrieval_token = \"[New Retrieval]\"\n",
    "        aug_prompts =  [\"<paragraph>{}</paragraph>\".format(paragraph)]\n",
    "    else:\n",
    "        retrieval_token = \"[Continue to Retrieve Evidence]\"\n",
    "        aug_prompts =  [\"<paragraph>{}</paragraph>\".format(paragraph)]\n",
    "    \n",
    "    pred = model.generate(prompt + retrieval_token + aug_prompts[0], sampling_params)[0]\n",
    "    pred_token_ids = pred.outputs[0].token_ids\n",
    "    pred_text_1 = pred.outputs[0].text\n",
    "    pred_log_probs = pred.outputs[0].logprobs\n",
    "    seq_score = pred.outputs[0].cumulative_logprob / \\\n",
    "        max(len(pred.outputs[0].token_ids), 1)\n",
    "    relevance_indices = []\n",
    "    for tok_idx, tok in enumerate(pred_token_ids):\n",
    "        if tok in rel_tokens.values():\n",
    "            relevance_indices.append(tok_idx)\n",
    "    if len(relevance_indices) > 0:\n",
    "        for idx in relevance_indices:\n",
    "            for token, token_id in rel_tokens.items():\n",
    "                prob = pred_log_probs[idx][token_id].logprob if token_id in pred_log_probs[idx] else -100\n",
    "                rel_score_dict[token] = np.exp(prob)\n",
    "    relevance_score = rel_score_dict['[Fully Relevant]']+ rel_score_dict['[Partially Relevant]'] / np.sum(list(rel_score_dict.values()))\n",
    "    processed_pred = pred_text_1.split('[Retrieve Entity]')[0]\n",
    "    matches =  dict(re.findall(pattern,processed_pred))\n",
    "    \n",
    "    name2id = dict()\n",
    "    entity_prompts = []\n",
    "    for _, entity in enumerate(topic_entity):\n",
    "        entities = []\n",
    "        for k, v in matches.items():\n",
    "            if v in ['Fully Relevant', 'Partially Relevant']:\n",
    "                another_entities = get_another_entity(entity, k, return_label=True)\n",
    "                # print(another_entities)\n",
    "                name2id.update(another_entities)\n",
    "                entities.extend([f'({get_label(entity)}, {k}, {e})' for e in another_entities.values()])\n",
    "        entity_prompts.append(aug_prompts[0] + processed_pred +  '[Retrieve Entity]' + \"<paragraph>{}</paragraph>\".format(';'.join(entities[:10])))\n",
    "    # print(aug_prompts)\n",
    "    preds = model.generate([prompt + retrieval_token+ entity_prompts[i] for i in range(len(entity_prompts))], sampling_params)\n",
    "    \n",
    "    for p_idx, pred in enumerate(preds):\n",
    "        pred_token_ids = pred.outputs[0].token_ids\n",
    "        pred_text_2 = pred.outputs[0].text\n",
    "        pred_log_probs = pred.outputs[0].logprobs\n",
    "        rel_score_dict = {}\n",
    "        relevance_indices = []\n",
    "        for tok_idx, tok in enumerate(pred_token_ids):\n",
    "            if tok in rel_tokens.values():\n",
    "                relevance_indices.append(tok_idx)\n",
    "        if len(relevance_indices) > 0:\n",
    "            # print(relevance_indices)\n",
    "            for idx in relevance_indices:\n",
    "                for token, token_id in rel_tokens.items():\n",
    "                    prob = pred_log_probs[idx][token_id].logprob if token_id in pred_log_probs[idx] else -100\n",
    "                    rel_score_dict[token] = np.exp(prob)\n",
    "        overall_scores[p_idx] = relevance_score + rel_score_dict['[Fully Relevant]'] + rel_score_dict['[Partially Relevant]']/ np.sum(list(rel_score_dict.values()))\n",
    "        if '[Continue to Retrieve Evidence]' in pred_text_2:\n",
    "            processed_pred = pred_text_2.split('[Continue to Retrieve Evidence]')[0]\n",
    "            matches =  dict(re.findall(pattern, processed_pred))\n",
    "            for k, v in matches.items():\n",
    "                if v in ['Fully Relevant', 'Partially Relevant']:\n",
    "                    if k in name2id:\n",
    "                        return_entities.append(name2id[k])\n",
    "            processed_pred += '[Continue to Retrieve Evidence]'\n",
    "        else:\n",
    "            processed_pred = pred_text_2\n",
    "        final_preds.append(aug_prompts[0] + processed_pred)\n",
    "    return final_preds, [overall_scores[p_idx] for p_idx in overall_scores], return_entities\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1639\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./data/merged/WebQSP_test.json', 'r',encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3531\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./data/merged/CWQ_test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking_prediction_tree(levels: dict[int,list[int]], curr_depth: int, prediction_tree: dict[int, dict]) -> dict[int,list[int]]:\n",
    "    '''\n",
    "    get best tracking from prediction_tree base on levels\n",
    "    '''\n",
    "    parent = 0 \n",
    "    best_selections = {}\n",
    "    # Traverse from the bottom \n",
    "    levels = {k: v for k, v in levels.items() if len(v) > 0 and k != 0} # remove empty list in levels\n",
    "    for path_i, node in enumerate(levels[len(levels)]): # beam search \n",
    "        if node == 0:\n",
    "            break\n",
    "        best_selections[path_i] = [node] \n",
    "        current_node = node \n",
    "        current_level = curr_depth \n",
    "        if current_node is None:\n",
    "            continue\n",
    "        while current_level > 0 and current_node is not None:\n",
    "            parent = prediction_tree[current_node][\"parent\"]\n",
    "            best_selections[path_i] = [parent] + best_selections[path_i] \n",
    "            current_node = parent \n",
    "            current_level -= 1\n",
    "    return best_selections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selections = backtracking_prediction_tree(levels, curr_depth, prediction_tree)\n",
    "final_prediction = {}\n",
    "splitted_sentences = {}\n",
    "original_splitted_sentences = {}\n",
    "ctxs = {}\n",
    "for path_i, nodes in best_selections.items():\n",
    "    final_prediction[path_i] = \" \".join([prediction_tree[node][\"processed_pred\"] for node in nodes if node is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "def save_to_json(data: List, data_path=''):\n",
    "    if not os.path.isfile(data_path):\n",
    "        # 文件不存在，创建新列表并写入文件\n",
    "        with open(data_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        return\n",
    "    try:\n",
    "        # 尝试读取现有文件\n",
    "        with open(data_path, 'r', encoding='utf-8') as file:\n",
    "            # 加载现有的JSON数据\n",
    "            existing_data = json.load(file)\n",
    "            existing_data.extend(data)\n",
    "    except json.JSONDecodeError:\n",
    "        # 文件不是有效的JSON，打印错误信息并退出\n",
    "        print(f\"文件 {data_path} 不是有效的JSON格式。\")\n",
    "        return\n",
    "    except ValueError as e:\n",
    "        # 打印错误信息并退出\n",
    "        print(e)\n",
    "        return\n",
    "    # 将更新后的数据写回文件\n",
    "    with open(data_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(existing_data, file, ensure_ascii=False, indent=4)\n",
    "def random_sample(lst, k=3):\n",
    "    try:\n",
    "        # 尝试从列表中随机抽取k个不重复的元素\n",
    "        return random.sample(lst, k)\n",
    "    except ValueError:\n",
    "        # 如果列表长度小于k，返回整个列表\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from src.sparql_utils import *\n",
    "import random\n",
    "def run_relation_generation_batch(model, prompt, new_retrieval, context, topic_entity, hypo=True, use_1hop=True):\n",
    "    rel_score_dict = {}\n",
    "    final_preds = []\n",
    "    overall_scores = []\n",
    "    final_contexts = []\n",
    "    if new_retrieval:\n",
    "        retrieval_token = \"[New Retrieval]\"\n",
    "    else:\n",
    "        retrieval_token = \"[Continue to Retrieve Evidence]\"\n",
    "    if use_1hop:\n",
    "        candidate_relations = []\n",
    "        for entity in topic_entity:\n",
    "            try:\n",
    "                candidate_relations.extend(get_1hop_relations_with_odbc(entity))\n",
    "            except:\n",
    "                continue\n",
    "        if len(candidate_relations):\n",
    "            vec_db = FAISS.from_texts(candidate_relations, cached_embedder)\n",
    "        else:\n",
    "            vec_db = all_db\n",
    "        retriever = vec_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "    else:\n",
    "        retriever = all_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "    paragraph = [page.page_content.strip() for page in retriever.invoke(prompt.split('\\n\\n')[1].split('<|eot_id|>')[0] + ' '+ context)]\n",
    "    if hypo:\n",
    "        hypo_rel = model.generate(prompt + retrieval_token, sampling_params)[0].outputs[0].text\n",
    "        pattern = r'(\\w+\\.\\w+\\.\\w+)\\[(.*?)\\]'\n",
    "        if '[Retrieve Entity]' in hypo_rel:\n",
    "            hypo_rel = hypo_rel.split('[Retrieve Entity]')[0]\n",
    "        matches =  dict(re.findall(pattern, hypo_rel))\n",
    "        string = ''\n",
    "        for k,v in matches.items():\n",
    "            if v in ['Fully Relevant', 'Partially Relevant']:\n",
    "                string += k + ' '\n",
    "        for extra_rel in retriever.invoke(string):\n",
    "            if extra_rel.page_content.strip() not in paragraph:\n",
    "                paragraph.append(extra_rel.page_content.strip())\n",
    "    \n",
    "    aug_prompts =  [\"<paragraph>{}</paragraph>\".format(';'.join(p))  for p in [paragraph[i: i+5] for i in range(0, len(paragraph), 5)]]\n",
    "    \n",
    "    preds = model.generate([prompt + retrieval_token + aug for aug in aug_prompts], sampling_params)\n",
    "    for p_id, pred in enumerate(preds):\n",
    "        pred_token_ids = pred.outputs[0].token_ids\n",
    "        pred_text_1 = pred.outputs[0].text\n",
    "        pred_log_probs = pred.outputs[0].logprobs\n",
    "        seq_score = pred.outputs[0].cumulative_logprob / \\\n",
    "            max(len(pred.outputs[0].token_ids), 1)\n",
    "        relevance_indices = []\n",
    "        for tok_idx, tok in enumerate(pred_token_ids):\n",
    "            if tok in rel_tokens.values():\n",
    "                relevance_indices.append(tok_idx)\n",
    "        if len(relevance_indices) > 0:\n",
    "            for idx in relevance_indices:\n",
    "                for token, token_id in rel_tokens.items():\n",
    "                    prob = pred_log_probs[idx][token_id].logprob if token_id in pred_log_probs[idx] else -100\n",
    "                    rel_score_dict[token] = np.exp(prob)\n",
    "        relevance_score = rel_score_dict['[Fully Relevant]']+ rel_score_dict['[Partially Relevant]'] / np.sum(list(rel_score_dict.values()))\n",
    "        if '[Retrieve Entity]' in pred_text_1:\n",
    "            processed_pred = pred_text_1.split('[Retrieve Entity]')[0] + '[Retrieve Entity]'\n",
    "        else:\n",
    "            processed_pred = pred_text_1\n",
    "        final_preds.append(retrieval_token + aug_prompts[p_id] + processed_pred)\n",
    "        overall_scores.append(relevance_score)\n",
    "        final_contexts.append(pred_text_1.split('[Retrieve Entity]')[0])\n",
    "\n",
    "    return final_preds, overall_scores, final_contexts\n",
    "\n",
    "def run_entity_generation_batch(model, prompt, topic_entity, context, score_type='hard'):\n",
    "    final_preds = []\n",
    "    overall_scores = {}\n",
    "    final_entities = []\n",
    "    final_context = []\n",
    "    pattern = r'(.*?)\\[(.*?)\\]'\n",
    "    matches =  dict(re.findall(pattern,context))\n",
    "    name2id = {}\n",
    "    effective_count = 0\n",
    "    entity_prompts = []\n",
    "    for _, entity in enumerate(topic_entity):\n",
    "        for k, v in matches.items():\n",
    "            if v in ['Fully Relevant', 'Partially Relevant']:\n",
    "                entities = []\n",
    "                try:\n",
    "                    another_entities = get_another_entity(entity, k, return_label=True)\n",
    "                except:\n",
    "                    another_entities = []\n",
    "                # handle Unkown mid entities\n",
    "                # whether mix another entities\n",
    "                if len(another_entities):\n",
    "                    name2id.setdefault(effective_count, {})\n",
    "                    name2id[effective_count].update(another_entities)\n",
    "                    effective_count += 1\n",
    "                    entities.extend([f'({get_label(entity)}, {k}, {e})' for e in another_entities.keys()])\n",
    "                    entity_prompts.append(\"<paragraph>{}</paragraph>\".format(';'.join(entities[:5])))\n",
    "    # print(aug_prompts)\n",
    "    preds = model.generate([prompt+  '[Retrieve Entity]' + entity_prompts[i] for i in range(len(entity_prompts))], sampling_params)\n",
    "    \n",
    "    for p_idx, pred in enumerate(preds):\n",
    "        return_entities = dict()\n",
    "        pred_token_ids = pred.outputs[0].token_ids\n",
    "        pred_text_2 = pred.outputs[0].text\n",
    "        pred_log_probs = pred.outputs[0].logprobs\n",
    "        # hard decode 分数\n",
    "        rel_score = 0\n",
    "        # rel_score_dict = {}\n",
    "        # relevance_indices = []\n",
    "        # for tok_idx, tok in enumerate(pred_token_ids):\n",
    "        #     if tok in rel_tokens.values():\n",
    "        #         relevance_indices.append(tok_idx)\n",
    "        # if len(relevance_indices) > 0:\n",
    "        #     # print(relevance_indices)\n",
    "        #     for idx in relevance_indices:\n",
    "        #         for token, token_id in rel_tokens.items():\n",
    "        #             prob = pred_log_probs[idx][token_id].logprob if token_id in pred_log_probs[idx] else -100\n",
    "        #             rel_score_dict[token] = np.exp(prob)\n",
    "        # if len(rel_score_dict) == 3:\n",
    "        #     overall_scores[p_idx] = rel_score_dict['[Fully Relevant]'] + rel_score_dict['[Partially Relevant]']/ np.sum(list(rel_score_dict.values()))\n",
    "        if '[Continue to Retrieve Evidence]' in pred_text_2:\n",
    "            processed_pred = pred_text_2.split('[Continue to Retrieve Evidence]')[0]\n",
    "            matches =  dict(re.findall(pattern, processed_pred))\n",
    "            for k, v in matches.items():\n",
    "                if v in ['Fully Relevant', 'Partially Relevant']:\n",
    "                    if k in name2id[p_idx]:\n",
    "                        return_entities[k] = name2id[p_idx][k]\n",
    "                    elif k == 'Unknown Entity':\n",
    "                        random_key = random_sample(list(name2id[p_idx].keys()))\n",
    "                        return_entities[random_key] = name2id[p_idx][random_key]\n",
    "                    rel_score += 1 if v =='Fully Relevant' else 0.5\n",
    "            processed_pred += '[Continue to Retrieve Evidence]'\n",
    "\n",
    "        elif '[No Retrieval]' in pred_text_2:\n",
    "            processed_pred = pred_text_2\n",
    "            rel_score += 100\n",
    "        else:\n",
    "            processed_pred = '[No Retrieval]'\n",
    "        overall_scores[p_idx] = rel_score\n",
    "        final_preds.append('[Retrieve Entity]' + entity_prompts[p_idx]+processed_pred)\n",
    "        final_entities.append(list(return_entities.values()))\n",
    "        final_context.append(' '.join(return_entities.keys()))\n",
    "    return final_preds, [overall_scores[p_idx] for p_idx in overall_scores], final_entities, final_context\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3208"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it, est. speed input: 27.37 toks/s, output: 97.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, est. speed input: 74.11 toks/s, output: 108.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.18it/s, est. speed input: 237.27 toks/s, output: 217.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, est. speed input: 127.35 toks/s, output: 111.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s, est. speed input: 307.68 toks/s, output: 212.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 121.91 toks/s, output: 110.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.15it/s, est. speed input: 300.13 toks/s, output: 215.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:00<00:00,  3.40it/s, est. speed input: 847.33 toks/s, output: 149.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 490.80 toks/s, output: 213.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:00<00:00,  3.43it/s, est. speed input: 842.48 toks/s, output: 151.30 toks/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "correct_ids = []\n",
    "logging_res = []\n",
    "for index in range(21, len(test_data)):\n",
    "# index = 483\n",
    "    hit = 0\n",
    "    print(f'Process {index}')\n",
    "    data_input = test_data[index]['question']\n",
    "    prompt = PROMPT_DICT['llama3'].format(input= data_input)\n",
    "    max_depth = 9\n",
    "    topic_entity = list(test_data[index]['gold_entity_map'].keys())\n",
    "    # pred = model.generate([prompt], sampling_params)[0]\n",
    "    # pred_text = pred.outputs[0].text\n",
    "    # if '[New Retrieval]' in pred_text:\n",
    "    curr_depth = 1\n",
    "    terminated = False\n",
    "    node_id = 0\n",
    "    prediction_tree = {}\n",
    "    levels = {}\n",
    "    prediction_tree[node_id] = {\"prompt\": prompt, \"pred\": \"[New Retrieval]\",\n",
    "                                \"processed_pred\": \"\", \"score\": None, \"topic_entity\": topic_entity, \"parent\": None, \"context\": ''}\n",
    "    levels[0] = [0]\n",
    "    while curr_depth < max_depth:\n",
    "        levels[curr_depth] = []\n",
    "        if curr_depth-1 in levels:\n",
    "            for node in levels[curr_depth-1]:\n",
    "                curr_pred = prediction_tree[node][\"pred\"]\n",
    "                if \"<|eot_id|>\" in curr_pred:\n",
    "                    continue\n",
    "                prompt = prediction_tree[node][\"prompt\"]\n",
    "                prev_generation = prediction_tree[node][\"processed_pred\"]\n",
    "                score = prediction_tree[node][\"score\"]\n",
    "                topic_entity = prediction_tree[node][\"topic_entity\"]\n",
    "                context = prediction_tree[node]['context']\n",
    "                cur_prompt = prompt + prev_generation\n",
    "                if \"Retrieve Entity\" in curr_pred.split('[')[-1]:\n",
    "                    retrieval_results = {}\n",
    "                    preds, scores, next_entities, contexts = run_entity_generation_batch(\n",
    "                        model, cur_prompt, topic_entity, context)\n",
    "                    for i, (pred, p_score,next_topic, context) in enumerate(zip(preds, scores, next_entities, contexts)):\n",
    "                        retrieval_results[i] = {\n",
    "                            \"pred\": pred, \"score\": p_score, \"next_topic\": next_topic, \"context\": context}\n",
    "\n",
    "                    for i, result in retrieval_results.items():\n",
    "                        node_id += 1\n",
    "                        node_score = result[\"score\"] * \\\n",
    "                            score if score is not None else result[\"score\"]\n",
    "                        pred = result[\"pred\"]\n",
    "                        next_entity = result['next_topic']\n",
    "                        if len(next_entity) == 0:\n",
    "                            next_entity = topic_entity\n",
    "                        prediction_tree[node_id] = {\"prompt\": cur_prompt, \"pred\": pred, \"context\": result['context'],\n",
    "                                                    \"score\": node_score, \"parent\": node,\n",
    "                                                    \"topic_entity\": next_entity}\n",
    "                        if \"[Continue to Retrieve Evidence]\" in pred:\n",
    "                            gen_result_index = pred.index(\"[Continue to Retrieve Evidence]\")\n",
    "                            prev_generation = pred[:gen_result_index]\n",
    "                        else:\n",
    "                            prev_generation = pred\n",
    "                        prediction_tree[node_id][\"processed_pred\"] = prev_generation\n",
    "                        levels[curr_depth].append(node_id)\n",
    "                #存在前后逻辑粘连   \n",
    "                if \"New Retrieval\" in curr_pred.split('[')[-1] or \"Continue to Retrieve Evidence\" in curr_pred.split('[')[-1]:\n",
    "                    retrieval_results = {}\n",
    "                    preds, scores, contexts = run_relation_generation_batch(\n",
    "                        model, cur_prompt, new_retrieval=True if (\"[New Retrieval]\" in curr_pred) else False, context=context, topic_entity=topic_entity, hypo=True)\n",
    "                    for i, (pred, p_score, context) in enumerate(zip(preds, scores, contexts)):\n",
    "                        retrieval_results[i] = {\n",
    "                            \"pred\": pred, \"score\": p_score, \"context\": context}\n",
    "\n",
    "                    for i, result in retrieval_results.items():\n",
    "                        node_id += 1\n",
    "                        node_score = result[\"score\"] * \\\n",
    "                            score if score is not None else result[\"score\"]\n",
    "                        pred = result[\"pred\"]\n",
    "                        context = result[\"context\"]\n",
    "                        prediction_tree[node_id] = {\"prompt\": cur_prompt, \"pred\": pred,\n",
    "                                                    \"score\": node_score, \"parent\": node,\n",
    "                                                    \"topic_entity\": topic_entity, \"context\": context}\n",
    "                        if \"[Retrieve Entity]\" in pred:\n",
    "                            gen_result_index = pred.index(\"[Retrieve Entity]\")\n",
    "                            prev_generation = pred[:gen_result_index]\n",
    "                        else:\n",
    "                            prev_generation = pred\n",
    "                        prediction_tree[node_id][\"processed_pred\"] = prev_generation\n",
    "                        levels[curr_depth].append(node_id)\n",
    "            current_rank = levels[curr_depth]\n",
    "            node2score = {\n",
    "                node_id: prediction_tree[node_id][\"score\"] for node_id in current_rank}\n",
    "            top_nodes = sorted(node2score.items(), key=lambda x: x[1], reverse=True)[\n",
    "                :3]\n",
    "            levels[curr_depth] = [node[0] for node in top_nodes]\n",
    "            curr_depth += 1\n",
    "        else:\n",
    "            break\n",
    "    labels = [get_label(ans) if ans.startswith('m.') else ans for ans in test_data[index]['answer']]\n",
    "    # print(labels)\n",
    "    for tree_node in prediction_tree.values():\n",
    "        if 'Answer' in tree_node['processed_pred']:\n",
    "            answer = tree_node['processed_pred'].split('Answer:')[-1]\n",
    "            for label in labels:\n",
    "                if label and label in answer:\n",
    "                    hit = 1\n",
    "    if hit == 1:\n",
    "        print('Correct')\n",
    "        count += 1\n",
    "        correct_ids.append(index)\n",
    "    else:\n",
    "        break\n",
    "        logging_res.append({\"index\": index, \"tree\": prediction_tree})\n",
    "    if len(logging_res) == 20:\n",
    "        save_to_json(logging_res, './output/inference/cwq_test_res_1217.json')\n",
    "        logging_res = []\n",
    "#1217修改了relation-1hop,修改了score\n",
    "save_to_json(logging_res, './output/inference/cwq_test_res_1217.json')\n",
    "    #注意有value标签, e.g. WebQTest-31\n",
    "    # for label in labels:\n",
    "    #     if label and label in prediction_tree[len(prediction_tree)-1]['processed_pred']:\n",
    "    #         count += 1\n",
    "    #         break\n",
    "    # except:\n",
    "    #     print(f'{index} Error')\n",
    "    #     continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./output/inference/correct_cwq.json', 'w') as f:\n",
    "    json.dump(correct_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0], 1: [1, 2], 2: [3], 3: [4, 5], 4: [6, 8, 7]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abstract': 'base.type_ontology.abstract',\n",
       " 'Non-Agent': 'base.type_ontology.non_agent',\n",
       " 'Topic': 'common.topic',\n",
       " 'Government Office or Title': 'government.government_office_or_title'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_another_entity('m.0j5wjnc', 'type.type.instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>',\n",
       "  'pred': '[New Retrieval]',\n",
       "  'processed_pred': '',\n",
       "  'score': None,\n",
       "  'topic_entity': ['m.01mp', 'm.0bzt6c'],\n",
       "  'parent': None,\n",
       "  'context': ''},\n",
       " 1: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>',\n",
       "  'pred': '[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]',\n",
       "  'score': 1.0,\n",
       "  'parent': 0,\n",
       "  'topic_entity': ['m.01mp', 'm.0bzt6c'],\n",
       "  'context': 'time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant]',\n",
       "  'processed_pred': '[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant]'},\n",
       " 2: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "  'context': 'Asia',\n",
       "  'score': 0.5,\n",
       "  'parent': 1,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant]'},\n",
       " 3: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(ASEAN Common Time Zone, location.location.time_zones, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "  'context': 'Asia',\n",
       "  'score': 0.5,\n",
       "  'parent': 1,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(ASEAN Common Time Zone, location.location.time_zones, Asia)</paragraph>Asia[Partially Relevant]'},\n",
       " 4: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant]',\n",
       "  'pred': '[Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant][Retrieve Entity]',\n",
       "  'score': 0.5,\n",
       "  'parent': 2,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'context': 'location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'processed_pred': '[Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]'},\n",
       " 5: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant]',\n",
       "  'pred': '[Continue to Retrieve Evidence]<paragraph>location.location.partially_contains;location.location.partiallycontains;location.location.partially_containedby</paragraph>location.location.partially_contains[Fully Relevant]location.location.partially_containedby[Partially Relevant]location.location.partiallycontains[Unrelevant][Retrieve Entity]',\n",
       "  'score': 0.5,\n",
       "  'parent': 2,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'context': 'location.location.partially_contains[Fully Relevant]location.location.partially_containedby[Partially Relevant]location.location.partiallycontains[Unrelevant]',\n",
       "  'processed_pred': '[Continue to Retrieve Evidence]<paragraph>location.location.partially_contains;location.location.partiallycontains;location.location.partially_containedby</paragraph>location.location.partially_contains[Fully Relevant]location.location.partially_containedby[Partially Relevant]location.location.partiallycontains[Unrelevant]'},\n",
       " 6: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, location.location.time_zones, Asia)</paragraph>Asia[Partially Relevant]',\n",
       "  'pred': '[Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant][Retrieve Entity]',\n",
       "  'score': 0.5,\n",
       "  'parent': 3,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'context': 'location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'processed_pred': '[Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]'},\n",
       " 7: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, location.location.time_zones, Asia)</paragraph>Asia[Partially Relevant]',\n",
       "  'pred': '[Continue to Retrieve Evidence]<paragraph>location.location.primarily_containedby;location.location.containedby;location.location.partially_containedby</paragraph>location.location.primarily_containedby[Fully Relevant]location.location.containedby[Partially Relevant]location.location.partially_containedby[Unrelevant][Retrieve Entity]',\n",
       "  'score': 0.5,\n",
       "  'parent': 3,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'context': 'location.location.primarily_containedby[Fully Relevant]location.location.containedby[Partially Relevant]location.location.partially_containedby[Unrelevant]',\n",
       "  'processed_pred': '[Continue to Retrieve Evidence]<paragraph>location.location.primarily_containedby;location.location.containedby;location.location.partially_containedby</paragraph>location.location.primarily_containedby[Fully Relevant]location.location.containedby[Partially Relevant]location.location.partially_containedby[Unrelevant]'},\n",
       " 8: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, location.statistical_region.population, m.0pcqnq3);(Asia, location.statistical_region.population, m.0qzk77g);(Asia, location.statistical_region.population, m.0wzzrlh);(Asia, location.statistical_region.population, m.0bmmmtv);(Asia, location.statistical_region.population, m.0pcqnqw)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "  'context': 'm.0bmmm1f',\n",
       "  'score': 0.25,\n",
       "  'parent': 4,\n",
       "  'topic_entity': ['m.0bmmm1f'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, location.statistical_region.population, m.0pcqnq3);(Asia, location.statistical_region.population, m.0qzk77g);(Asia, location.statistical_region.population, m.0wzzrlh);(Asia, location.statistical_region.population, m.0bmmmtv);(Asia, location.statistical_region.population, m.0pcqnqw)</paragraph>Unknown Entity[Partially Relevant]'},\n",
       " 9: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, time.time_zone.locations_in_this_time_zone, Taiwan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Iran Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Japan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Eastern European Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, India Time Zone)</paragraph>Taiwan Time Zone[Partially Relevant]Iran Time Zone[Partially Relevant]Japan Time Zone[Partially Relevant]Eastern European Time Zone[Unrelevant]India Time Zone[Partially Relevant][No Retrieval]Answer: Indonesia<|eot_id|>',\n",
       "  'context': '',\n",
       "  'score': 50.0,\n",
       "  'parent': 4,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, time.time_zone.locations_in_this_time_zone, Taiwan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Iran Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Japan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Eastern European Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, India Time Zone)</paragraph>Taiwan Time Zone[Partially Relevant]Iran Time Zone[Partially Relevant]Japan Time Zone[Partially Relevant]Eastern European Time Zone[Unrelevant]India Time Zone[Partially Relevant][No Retrieval]Answer: Indonesia<|eot_id|>'},\n",
       " 10: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, base.locations.countries.continent, Israel);(Asia, base.locations.countries.continent, Singapore);(Asia, base.locations.countries.continent, Japan);(Asia, base.locations.countries.continent, India);(Asia, base.locations.countries.continent, Indonesia)</paragraph>Israel[Unrelevant]Singapore[Partially Relevant]Japan[Partially Relevant]India[Partially Relevant]Indonesia[Partially Relevant][No Retrieval]Answer: Indonesia<|eot_id|>',\n",
       "  'context': '',\n",
       "  'score': 50.0,\n",
       "  'parent': 4,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, base.locations.countries.continent, Israel);(Asia, base.locations.countries.continent, Singapore);(Asia, base.locations.countries.continent, Japan);(Asia, base.locations.countries.continent, India);(Asia, base.locations.countries.continent, Indonesia)</paragraph>Israel[Unrelevant]Singapore[Partially Relevant]Japan[Partially Relevant]India[Partially Relevant]Indonesia[Partially Relevant][No Retrieval]Answer: Indonesia<|eot_id|>'},\n",
       " 11: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.partially_contains;location.location.partiallycontains;location.location.partially_containedby</paragraph>location.location.partially_contains[Fully Relevant]location.location.partially_containedby[Partially Relevant]location.location.partiallycontains[Unrelevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, location.location.partially_contains, Sepik River);(Asia, location.location.partially_contains, Fly River);(Asia, location.location.partially_contains, Ok Tedi River);(Asia, location.location.partially_contains, Tikhtengen);(Asia, location.location.partially_contains, Azhdahak)</paragraph>Sepik River[Relevant]Fly River[Relevant]Ok Tedi River[Relevant]Tikhtengen[Relevant]Azhdahak[Relevant][Continue to Retrieve Evidence]',\n",
       "  'context': '',\n",
       "  'score': 0.0,\n",
       "  'parent': 5,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, location.location.partially_contains, Sepik River);(Asia, location.location.partially_contains, Fly River);(Asia, location.location.partially_contains, Ok Tedi River);(Asia, location.location.partially_contains, Tikhtengen);(Asia, location.location.partially_contains, Azhdahak)</paragraph>Sepik River[Relevant]Fly River[Relevant]Ok Tedi River[Relevant]Tikhtengen[Relevant]Azhdahak[Relevant]'},\n",
       " 12: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, time.time_zone.locations_in_this_time_zone, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.partially_contains;location.location.partiallycontains;location.location.partially_containedby</paragraph>location.location.partially_contains[Fully Relevant]location.location.partially_containedby[Partially Relevant]location.location.partiallycontains[Unrelevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, location.location.partially_containedby, Sepik River);(Asia, location.location.partially_containedby, Fly River);(Asia, location.location.partially_containedby, Ok Tedi River);(Asia, location.location.partially_containedby, Tikhtengen);(Asia, location.location.partially_containedby, Azhdahak)</paragraph>Sepik River[Relevant]Fly River[Relevant]Ok Tedi River[Relevant]Tikhtengen[Relevant]Azhdahak[Relevant][Continue to Retrieve Evidence]',\n",
       "  'context': '',\n",
       "  'score': 0.0,\n",
       "  'parent': 5,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, location.location.partially_containedby, Sepik River);(Asia, location.location.partially_containedby, Fly River);(Asia, location.location.partially_containedby, Ok Tedi River);(Asia, location.location.partially_containedby, Tikhtengen);(Asia, location.location.partially_containedby, Azhdahak)</paragraph>Sepik River[Relevant]Fly River[Relevant]Ok Tedi River[Relevant]Tikhtengen[Relevant]Azhdahak[Relevant]'},\n",
       " 13: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, location.location.time_zones, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, location.statistical_region.population, m.0pcqnq3);(Asia, location.statistical_region.population, m.0qzk77g);(Asia, location.statistical_region.population, m.0wzzrlh);(Asia, location.statistical_region.population, m.0bmmmtv);(Asia, location.statistical_region.population, m.0pcqnqw)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "  'context': 'm.0pcqnpy',\n",
       "  'score': 0.25,\n",
       "  'parent': 6,\n",
       "  'topic_entity': ['m.0pcqnpy'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, location.statistical_region.population, m.0pcqnq3);(Asia, location.statistical_region.population, m.0qzk77g);(Asia, location.statistical_region.population, m.0wzzrlh);(Asia, location.statistical_region.population, m.0bmmmtv);(Asia, location.statistical_region.population, m.0pcqnqw)</paragraph>Unknown Entity[Partially Relevant]'},\n",
       " 14: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, location.location.time_zones, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, time.time_zone.locations_in_this_time_zone, Taiwan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Iran Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Japan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Eastern European Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, India Time Zone)</paragraph>Taiwan Time Zone[Partially Relevant]Iran Time Zone[Partially Relevant]Japan Time Zone[Partially Relevant]Eastern European Time Zone[Unrelevant]India Time Zone[Partially Relevant][No Retrieval]Answer: Indonesia<|eot_id|>',\n",
       "  'context': '',\n",
       "  'score': 50.0,\n",
       "  'parent': 6,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, time.time_zone.locations_in_this_time_zone, Taiwan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Iran Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Japan Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, Eastern European Time Zone);(Asia, time.time_zone.locations_in_this_time_zone, India Time Zone)</paragraph>Taiwan Time Zone[Partially Relevant]Iran Time Zone[Partially Relevant]Japan Time Zone[Partially Relevant]Eastern European Time Zone[Unrelevant]India Time Zone[Partially Relevant][No Retrieval]Answer: Indonesia<|eot_id|>'},\n",
       " 15: {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhich country that is situated in the ASEAN Common Time Zone has the largest population?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>location.location.time_zones;time.time_zone.time_zone_name_standard;time.time_zone.time_zone_abbreviation_standard;time.time_zone.locations_in_this_time_zone;time.time_zone.offset_from_uct</paragraph>time.time_zone.locations_in_this_time_zone[Fully Relevant]location.location.time_zones[Partially Relevant]time.time_zone.time_zone_name_standard[Unrelevant][Retrieve Entity]<paragraph>(ASEAN Common Time Zone, location.location.time_zones, Asia)</paragraph>Asia[Partially Relevant][Continue to Retrieve Evidence]<paragraph>location.location.time_zones;location.statistical_region.population;time.time_zone.locations_in_this_time_zone;base.locations.countries.continent;base.locations.place_in_the_world.continent</paragraph>location.statistical_region.population[Fully Relevant]time.time_zone.locations_in_this_time_zone[Partially Relevant]base.locations.countries.continent[Partially Relevant]',\n",
       "  'pred': '[Retrieve Entity]<paragraph>(Asia, base.locations.countries.continent, Israel);(Asia, base.locations.countries.continent, Singapore);(Asia, base.locations.countries.continent, Japan);(Asia, base.locations.countries.continent, India);(Asia, base.locations.countries.continent, Indonesia)</paragraph>Israel[Unrelevant]Singapore[Partially Relevant]Japan[Partially Relevant]India[Partially Relevant]Indonesia[Fully Relevant][No Retrieval]Answer: Indonesia<|eot_id|>',\n",
       "  'context': '',\n",
       "  'score': 50.0,\n",
       "  'parent': 6,\n",
       "  'topic_entity': ['m.0j0k'],\n",
       "  'processed_pred': '[Retrieve Entity]<paragraph>(Asia, base.locations.countries.continent, Israel);(Asia, base.locations.countries.continent, Singapore);(Asia, base.locations.countries.continent, Japan);(Asia, base.locations.countries.continent, India);(Asia, base.locations.countries.continent, Indonesia)</paragraph>Israel[Unrelevant]Singapore[Partially Relevant]Japan[Partially Relevant]India[Partially Relevant]Indonesia[Fully Relevant][No Retrieval]Answer: Indonesia<|eot_id|>'}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UTC−04:00': 'm.0730gz', 'Atlantic Time Zone': 'm.042g7t'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_another_entity('m.027rn', 'location.location.time_zones')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eval_metric(best_pred, preds, answers):\n",
    "    correct, total = 0.0, 0.0\n",
    "    for entity in preds:\n",
    "        if entity in answers:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    if len(answers) == 0:\n",
    "        if total == 0:\n",
    "            return 1.0, 1.0, 1.0, 1.0 # precision, recall, f1, hits\n",
    "        else:\n",
    "            return 0.0, 1.0, 0.0, 1.0 # precision, recall, f1, hits\n",
    "    else:\n",
    "        hits = float(best_pred in answers)\n",
    "        if total == 0:\n",
    "            return 1.0, 0.0, 0.0, hits # precision, recall, f1, hits\n",
    "        else:\n",
    "            precision, recall = correct / total, correct / len(answers)\n",
    "            f1 = 2.0 / (1.0 / precision + 1.0 / recall) if precision != 0 and recall != 0 else 0.0\n",
    "            return precision, recall, f1, hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eval_metric(preds, answers):\n",
    "    correct, total = 0.0, 0.0\n",
    "    for entity in preds:\n",
    "        if entity in answers:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    # if len(answers) == 0:\n",
    "    #     if total == 0:\n",
    "    #         return 1.0, 1.0, 1.0, 1.0 # precision, recall, f1, hits\n",
    "    #     else:\n",
    "    #         return 0.0, 1.0, 0.0, 1.0 # precision, recall, f1, hits\n",
    "    # else:\n",
    "    if total != 0:\n",
    "        hits = 1\n",
    "    else: \n",
    "        hits = 0\n",
    "    if total == 0:\n",
    "        return 1.0, 0.0, 0.0, hits # precision, recall, f1, hits\n",
    "    else:\n",
    "        precision, recall = correct / total, correct / len(answers)\n",
    "        f1 = 2.0 / (1.0 / precision + 1.0 / recall) if precision != 0 and recall != 0 else 0.0\n",
    "        return precision, recall, f1, hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.3333333333333333, 0.5, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_eval_metric(preds, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it, est. speed input: 26.70 toks/s, output: 95.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, est. speed input: 72.83 toks/s, output: 107.10 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.16it/s, est. speed input: 235.46 toks/s, output: 216.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 126.31 toks/s, output: 110.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s, est. speed input: 307.54 toks/s, output: 212.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 122.65 toks/s, output: 111.50 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.16it/s, est. speed input: 301.70 toks/s, output: 216.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:00<00:00,  3.05it/s, est. speed input: 759.94 toks/s, output: 145.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 487.99 toks/s, output: 212.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:00<00:00,  3.41it/s, est. speed input: 835.67 toks/s, output: 150.08 toks/s]\n"
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "# correct_ids = []\n",
    "# logging_res = []\n",
    "# for index in range(21, len(test_data)):\n",
    "# # index = 483\n",
    "#     hit = 0\n",
    "#     print(f'Process {index}')\n",
    "#     data_input = test_data[index]['question']\n",
    "#     prompt = PROMPT_DICT['llama3'].format(input= data_input)\n",
    "#     max_depth = 5\n",
    "#     topic_entity = list(test_data[index]['gold_entity_map'].keys())\n",
    "#     # pred = model.generate([prompt], sampling_params)[0]\n",
    "#     # pred_text = pred.outputs[0].text\n",
    "#     # if '[New Retrieval]' in pred_text:\n",
    "#     curr_depth = 1\n",
    "#     terminated = False\n",
    "#     node_id = 0\n",
    "#     prediction_tree = {}\n",
    "#     levels = {}\n",
    "#     prediction_tree[node_id] = {\"prompt\": prompt, \"pred\": \"[New Retrieval]\",\n",
    "#                                 \"processed_pred\": \"\", \"score\": None, \"topic_entity\": topic_entity, \"parent\": None, \"context\": ''}\n",
    "#     levels[0] = [0]\n",
    "#     while curr_depth < max_depth:\n",
    "#         levels[curr_depth] = []\n",
    "#         if curr_depth-1 in levels:\n",
    "#             for node in levels[curr_depth-1]:\n",
    "#                 curr_pred = prediction_tree[node][\"pred\"]\n",
    "#                 if \"<|eot_id|>\" in curr_pred:\n",
    "#                     continue\n",
    "#                 prompt = prediction_tree[node][\"prompt\"]\n",
    "#                 prev_generation = prediction_tree[node][\"processed_pred\"]\n",
    "#                 score = prediction_tree[node][\"score\"]\n",
    "#                 topic_entity = prediction_tree[node][\"topic_entity\"]\n",
    "#                 context = prediction_tree[node]['context']\n",
    "#                 cur_prompt = prompt + prev_generation\n",
    "#                 if \"Retrieve Entity\" in curr_pred.split('[')[-1]:\n",
    "#                     retrieval_results = {}\n",
    "#                     preds, scores, next_entities, contexts = run_entity_generation_batch(\n",
    "#                         model, cur_prompt, topic_entity, context)\n",
    "#                     for i, (pred, p_score,next_topic, context) in enumerate(zip(preds, scores, next_entities, contexts)):\n",
    "#                         retrieval_results[i] = {\n",
    "#                             \"pred\": pred, \"score\": p_score, \"next_topic\": next_topic, \"context\": context}\n",
    "\n",
    "#                     for i, result in retrieval_results.items():\n",
    "#                         node_id += 1\n",
    "#                         node_score = result[\"score\"] * \\\n",
    "#                             score if score is not None else result[\"score\"]\n",
    "#                         pred = result[\"pred\"]\n",
    "#                         next_entity = result['next_topic']\n",
    "#                         if len(next_entity) == 0:\n",
    "#                             next_entity = topic_entity\n",
    "#                         prediction_tree[node_id] = {\"prompt\": cur_prompt, \"pred\": pred, \"context\": result['context'],\n",
    "#                                                     \"score\": node_score, \"parent\": node,\n",
    "#                                                     \"topic_entity\": next_entity}\n",
    "#                         if \"[Continue to Retrieve Evidence]\" in pred:\n",
    "#                             gen_result_index = pred.index(\"[Continue to Retrieve Evidence]\")\n",
    "#                             prev_generation = pred[:gen_result_index]\n",
    "#                         else:\n",
    "#                             prev_generation = pred\n",
    "#                         prediction_tree[node_id][\"processed_pred\"] = prev_generation\n",
    "#                         levels[curr_depth].append(node_id)\n",
    "#                 #存在前后逻辑粘连   \n",
    "#                 if \"New Retrieval\" in curr_pred.split('[')[-1] or \"Continue to Retrieve Evidence\" in curr_pred.split('[')[-1]:\n",
    "#                     retrieval_results = {}\n",
    "#                     preds, scores, contexts = run_relation_generation_batch(\n",
    "#                         model, cur_prompt, new_retrieval=True if (\"[New Retrieval]\" in curr_pred) else False, context=context, topic_entity=topic_entity, hypo=True)\n",
    "#                     for i, (pred, p_score, context) in enumerate(zip(preds, scores, contexts)):\n",
    "#                         retrieval_results[i] = {\n",
    "#                             \"pred\": pred, \"score\": p_score, \"context\": context}\n",
    "\n",
    "#                     for i, result in retrieval_results.items():\n",
    "#                         node_id += 1\n",
    "#                         node_score = result[\"score\"] * \\\n",
    "#                             score if score is not None else result[\"score\"]\n",
    "#                         pred = result[\"pred\"]\n",
    "#                         context = result[\"context\"]\n",
    "#                         prediction_tree[node_id] = {\"prompt\": cur_prompt, \"pred\": pred,\n",
    "#                                                     \"score\": node_score, \"parent\": node,\n",
    "#                                                     \"topic_entity\": topic_entity, \"context\": context}\n",
    "#                         if \"[Retrieve Entity]\" in pred:\n",
    "#                             gen_result_index = pred.index(\"[Retrieve Entity]\")\n",
    "#                             prev_generation = pred[:gen_result_index]\n",
    "#                         else:\n",
    "#                             prev_generation = pred\n",
    "#                         prediction_tree[node_id][\"processed_pred\"] = prev_generation\n",
    "#                         levels[curr_depth].append(node_id)\n",
    "#             current_rank = levels[curr_depth]\n",
    "#             node2score = {\n",
    "#                 node_id: prediction_tree[node_id][\"score\"] for node_id in current_rank}\n",
    "#             top_nodes = sorted(node2score.items(), key=lambda x: x[1], reverse=True)[\n",
    "#                 :3]\n",
    "#             levels[curr_depth] = [node[0] for node in top_nodes]\n",
    "#             curr_depth += 1\n",
    "#         else:\n",
    "#             break\n",
    "#     labels = [get_label(ans) if ans.startswith('m.') else ans for ans in test_data[index]['answer']]\n",
    "#     # print(labels)\n",
    "#     for tree_node in prediction_tree.values():\n",
    "#         if 'Answer' in tree_node['processed_pred']:\n",
    "#             answer = tree_node['processed_pred'].split('Answer:')[-1]\n",
    "#             for label in labels:\n",
    "#                 if label and label in answer:\n",
    "#                     hit = 1\n",
    "#     if hit == 1:\n",
    "#         print('Correct')\n",
    "#         count += 1\n",
    "#         correct_ids.append(index)\n",
    "#     else:\n",
    "#         break\n",
    "#         logging_res.append({\"index\": index, \"tree\": prediction_tree})\n",
    "#     if len(logging_res) == 20:\n",
    "#         save_to_json(logging_res, './output/inference/webqsp_test_res.json')\n",
    "#         logging_res = []\n",
    "\n",
    "#     #注意有value标签, e.g. WebQTest-31\n",
    "#     # for label in labels:\n",
    "#     #     if label and label in prediction_tree[len(prediction_tree)-1]['processed_pred']:\n",
    "#     #         count += 1\n",
    "#     #         break\n",
    "#     # except:\n",
    "#     #     print(f'{index} Error')\n",
    "#     #     continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./output/inference/cwq_test_res_1217.json', 'r', encoding='utf-8') as f:\n",
    "    cwq_result = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 {'index': 14, 'tree': {'0': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>', 'pred': '[New Retrieval]', 'processed_pred': '', 'score': None, 'topic_entity': ['m.0hhv_6h'], 'parent': None, 'context': ''}, '1': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>', 'pred': '[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]', 'score': 1.0, 'parent': 0, 'topic_entity': ['m.0hhv_6h'], 'context': 'business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant]', 'processed_pred': '[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant]'}, '2': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>', 'pred': '[New Retrieval]<paragraph>common.topic.notable_for</paragraph>common.topic.notable_for[Fully Relevant]baseball.lifetime_batting_statistics.last_statistics_season[Partially Relevant]baseball.baseball_team.current_coaches[Partially Relevant][Retrieve Entity]', 'score': 1.0, 'parent': 0, 'topic_entity': ['m.0hhv_6h'], 'context': 'common.topic.notable_for[Fully Relevant]baseball.lifetime_batting_statistics.last_statistics_season[Partially Relevant]baseball.baseball_team.current_coaches[Partially Relevant]', 'processed_pred': '[New Retrieval]<paragraph>common.topic.notable_for</paragraph>common.topic.notable_for[Fully Relevant]baseball.lifetime_batting_statistics.last_statistics_season[Partially Relevant]baseball.baseball_team.current_coaches[Partially Relevant]'}, '3': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant]', 'pred': '[Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]', 'context': 'm.011zsc4_', 'score': 0.5, 'parent': 1, 'topic_entity': ['m.011zsc4_'], 'processed_pred': '[Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant]'}, '4': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant]', 'pred': '[Retrieve Entity]<paragraph>(Larry Baer, organization.leadership.person, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]', 'context': 'm.011zsc4_', 'score': 0.5, 'parent': 1, 'topic_entity': ['m.011zsc4_'], 'processed_pred': '[Retrieve Entity]<paragraph>(Larry Baer, organization.leadership.person, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant]'}, '5': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>common.topic.notable_for</paragraph>common.topic.notable_for[Fully Relevant]baseball.lifetime_batting_statistics.last_statistics_season[Partially Relevant]baseball.baseball_team.current_coaches[Partially Relevant]', 'pred': '[Retrieve Entity]<paragraph>(Larry Baer, common.topic.notable_for, g.1255l_47c)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]', 'context': 'g.1255l_47c', 'score': 0.5, 'parent': 2, 'topic_entity': ['g.1255l_47c'], 'processed_pred': '[Retrieve Entity]<paragraph>(Larry Baer, common.topic.notable_for, g.1255l_47c)</paragraph>Unknown Entity[Partially Relevant]'}, '6': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant]', 'pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant][Retrieve Entity]', 'score': 0.5, 'parent': 3, 'topic_entity': ['m.011zsc4_'], 'context': 'organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]', 'processed_pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]'}, '7': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant]', 'pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.organization;organization.leadership.role</paragraph>organization.leadership.organization[Fully Relevant]organization.leadership.role[Partially Relevant]m.011zsc4_[Unrelevant][Retrieve Entity]', 'score': 0.5, 'parent': 3, 'topic_entity': ['m.011zsc4_'], 'context': 'organization.leadership.organization[Fully Relevant]organization.leadership.role[Partially Relevant]m.011zsc4_[Unrelevant]', 'processed_pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.organization;organization.leadership.role</paragraph>organization.leadership.organization[Fully Relevant]organization.leadership.role[Partially Relevant]m.011zsc4_[Unrelevant]'}, '8': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, organization.leadership.person, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant]', 'pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant][Retrieve Entity]', 'score': 0.5, 'parent': 4, 'topic_entity': ['m.011zsc4_'], 'context': 'organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]', 'processed_pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]'}, '9': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, organization.leadership.person, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant]', 'pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.organization</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>business.board_member.leader_of;organization.leadership.organization;organization.leadership.person;organization.organization.leadership;baseball.baseball_league.teams;organization.leadership_relationship.organization</paragraph>organization.leadership.organization[Fully Relevant]organization.leadership.person[Partially Relevant]baseball.baseball_league.teams[Partially Relevant][Retrieve Entity]', 'score': 0.5, 'parent': 4, 'topic_entity': ['m.011zsc4_'], 'context': 'Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>business.board_member.leader_of;organization.leadership.organization;organization.leadership.person;organization.organization.leadership;baseball.baseball_league.teams;organization.leadership_relationship.organization</paragraph>organization.leadership.organization[Fully Relevant]organization.leadership.person[Partially Relevant]baseball.baseball_league.teams[Partially Relevant]', 'processed_pred': '[Continue to Retrieve Evidence]<paragraph>organization.leadership.organization</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>business.board_member.leader_of;organization.leadership.organization;organization.leadership.person;organization.organization.leadership;baseball.baseball_league.teams;organization.leadership_relationship.organization</paragraph>organization.leadership.organization[Fully Relevant]organization.leadership.person[Partially Relevant]baseball.baseball_league.teams[Partially Relevant]'}, '10': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>common.topic.notable_for</paragraph>common.topic.notable_for[Fully Relevant]baseball.lifetime_batting_statistics.last_statistics_season[Partially Relevant]baseball.baseball_team.current_coaches[Partially Relevant][Retrieve Entity]<paragraph>(Larry Baer, common.topic.notable_for, g.1255l_47c)</paragraph>Unknown Entity[Partially Relevant]', 'pred': '[Continue to Retrieve Evidence]<paragraph>common.notable_for.predicate;common.topic.notable_for;common.notable_for.display_name;common.notable_for.object;common.notable_for.notable_object</paragraph>common.topic.notable_for[Fully Relevant]common.notable_for.object[Fully Relevant]common.notable_for.notable_object[Partially Relevant][Retrieve Entity]', 'score': 0.5, 'parent': 5, 'topic_entity': ['g.1255l_47c'], 'context': 'common.topic.notable_for[Fully Relevant]common.notable_for.object[Fully Relevant]common.notable_for.notable_object[Partially Relevant]', 'processed_pred': '[Continue to Retrieve Evidence]<paragraph>common.notable_for.predicate;common.topic.notable_for;common.notable_for.display_name;common.notable_for.object;common.notable_for.notable_object</paragraph>common.topic.notable_for[Fully Relevant]common.notable_for.object[Fully Relevant]common.notable_for.notable_object[Partially Relevant]'}, '11': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]', 'pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.person, Larry Baer)</paragraph>m.011zsc4_[Partially Relevant][Continue to Retrieve Evidence]', 'context': '', 'score': 0.25, 'parent': 6, 'topic_entity': ['m.011zsc4_'], 'processed_pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.person, Larry Baer)</paragraph>m.011zsc4_[Partially Relevant]'}, '12': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]', 'pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.from, 2012-01-01)</paragraph>2012-01-01[Fully Relevant][No Retrieval]Answer: 2012-01-01<|eot_id|>', 'context': '', 'score': 50.0, 'parent': 6, 'topic_entity': ['m.011zsc4_'], 'processed_pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.from, 2012-01-01)</paragraph>2012-01-01[Fully Relevant][No Retrieval]Answer: 2012-01-01<|eot_id|>'}, '13': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>organization.leadership.organization;organization.leadership.role</paragraph>organization.leadership.organization[Fully Relevant]organization.leadership.role[Partially Relevant]m.011zsc4_[Unrelevant]', 'pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.organization, San Francisco Giants)</paragraph>San Francisco Giants[Partially Relevant][Continue to Retrieve Evidence]', 'context': 'San Francisco Giants', 'score': 0.25, 'parent': 7, 'topic_entity': ['m.0713r'], 'processed_pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.organization, San Francisco Giants)</paragraph>San Francisco Giants[Partially Relevant]'}, '14': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, business.board_member.leader_of, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>organization.leadership.organization;organization.leadership.role</paragraph>organization.leadership.organization[Fully Relevant]organization.leadership.role[Partially Relevant]m.011zsc4_[Unrelevant]', 'pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.role, CEO)</paragraph>m.011zsc4_[Unrelevant][Continue to Retrieve Evidence]', 'context': '', 'score': 0.0, 'parent': 7, 'topic_entity': ['m.011zsc4_'], 'processed_pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.role, CEO)</paragraph>m.011zsc4_[Unrelevant]'}, '15': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, organization.leadership.person, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]', 'pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.person, Larry Baer)</paragraph>m.011zsc4_[Partially Relevant][Continue to Retrieve Evidence]', 'context': '', 'score': 0.25, 'parent': 8, 'topic_entity': ['m.011zsc4_'], 'processed_pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.person, Larry Baer)</paragraph>m.011zsc4_[Partially Relevant]'}, '16': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhen was the last time a team led by Larr Baer win the World Series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>business.board_member.leader_of;organization.leadership.person;common.topic.article;people.person.gender;common.topic.description</paragraph>business.board_member.leader_of[Fully Relevant]organization.leadership.person[Partially Relevant]common.topic.article[Unrelevant][Retrieve Entity]<paragraph>(Larry Baer, organization.leadership.person, m.011zsc4_)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>organization.leadership.title;organization.organization.leadership;organization.leadership.person;business.board_member.leader_of;organization.leadership.from</paragraph>organization.leadership.person[Fully Relevant]organization.leadership.title[Partially Relevant]organization.leadership.from[Partially Relevant]', 'pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.from, 2012-01-01)</paragraph>2012-01-01[Partially Relevant]m.011zsc4_[Relevant][No Retrieval]Answer: 2012-01-01<|eot_id|>', 'context': '', 'score': 50.0, 'parent': 8, 'topic_entity': ['m.011zsc4_'], 'processed_pred': '[Retrieve Entity]<paragraph>(m.011zsc4_, organization.leadership.from, 2012-01-01)</paragraph>2012-01-01[Partially Relevant]m.011zsc4_[Relevant][No Retrieval]Answer: 2012-01-01<|eot_id|>'}}}\n"
     ]
    }
   ],
   "source": [
    "for i, error in enumerate(result):\n",
    "    if error['index'] == 14:\n",
    "        print(i, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 32,\n",
       " 'tree': {'0': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>',\n",
       "   'pred': '[New Retrieval]',\n",
       "   'processed_pred': '',\n",
       "   'score': None,\n",
       "   'topic_entity': ['m.0g2lq', 'm.01064ngx'],\n",
       "   'parent': None,\n",
       "   'context': ''},\n",
       "  '1': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>',\n",
       "   'pred': '[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant][Retrieve Entity]',\n",
       "   'score': 1.0,\n",
       "   'parent': 0,\n",
       "   'topic_entity': ['m.0g2lq', 'm.01064ngx'],\n",
       "   'context': 'film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant]',\n",
       "   'processed_pred': '[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant]'},\n",
       "  '2': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>',\n",
       "   'pred': '[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant][Retrieve Entity]',\n",
       "   'score': 1.0,\n",
       "   'parent': 0,\n",
       "   'topic_entity': ['m.0g2lq', 'm.01064ngx'],\n",
       "   'context': 'film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant]',\n",
       "   'processed_pred': '[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant]'},\n",
       "  '3': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(Ron Howard, film.actor.film, m.0gz5dr6);(Ron Howard, film.actor.film, m.06z_4g2);(Ron Howard, film.actor.film, m.0gz5dg6);(Ron Howard, film.actor.film, m.0gz5dgj);(Ron Howard, film.actor.film, m.0gz5dqr)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "   'context': 'm.0cg88x1',\n",
       "   'score': 0.5,\n",
       "   'parent': 1,\n",
       "   'topic_entity': ['m.0cg88x1'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(Ron Howard, film.actor.film, m.0gz5dr6);(Ron Howard, film.actor.film, m.06z_4g2);(Ron Howard, film.actor.film, m.0gz5dg6);(Ron Howard, film.actor.film, m.0gz5dgj);(Ron Howard, film.actor.film, m.0gz5dqr)</paragraph>Unknown Entity[Partially Relevant]'},\n",
       "  '4': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(Ron Howard, film.film.produced_by, Beyond the Mat);(Ron Howard, film.film.produced_by, Clean and Sober);(Ron Howard, film.film.produced_by, Closet Land);(Ron Howard, film.film.produced_by, Inventing the Abbotts);(Ron Howard, film.film.produced_by, The Lost Symbol)</paragraph>Beyond the Mat[Unrelevant]Clean and Sober[Unrelevant]Closet Land[Unrelevant]Inventing the Abbotts[Unrelevant]The Lost Symbol[Unrelevant][No Retrieval]Answer: The Da Vinci Code<|eot_id|>',\n",
       "   'context': '',\n",
       "   'score': 100.0,\n",
       "   'parent': 1,\n",
       "   'topic_entity': ['m.0g2lq', 'm.01064ngx'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(Ron Howard, film.film.produced_by, Beyond the Mat);(Ron Howard, film.film.produced_by, Clean and Sober);(Ron Howard, film.film.produced_by, Closet Land);(Ron Howard, film.film.produced_by, Inventing the Abbotts);(Ron Howard, film.film.produced_by, The Lost Symbol)</paragraph>Beyond the Mat[Unrelevant]Clean and Sober[Unrelevant]Closet Land[Unrelevant]Inventing the Abbotts[Unrelevant]The Lost Symbol[Unrelevant][No Retrieval]Answer: The Da Vinci Code<|eot_id|>'},\n",
       "  '5': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gly_fg);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0crsy3m);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.011rjztp);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.010dn879);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gz5wf0)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "   'context': 'm.0gz5jnz',\n",
       "   'score': 0.5,\n",
       "   'parent': 2,\n",
       "   'topic_entity': ['m.0gz5jnz'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gly_fg);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0crsy3m);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.011rjztp);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.010dn879);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gz5wf0)</paragraph>Unknown Entity[Partially Relevant]'},\n",
       "  '6': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(Teklel Hafouli, film.film_character.portrayed_in_films, m.01064ngt)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "   'context': 'm.01064ngt',\n",
       "   'score': 0.5,\n",
       "   'parent': 2,\n",
       "   'topic_entity': ['m.01064ngt'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(Teklel Hafouli, film.film_character.portrayed_in_films, m.01064ngt)</paragraph>Unknown Entity[Partially Relevant]'},\n",
       "  '7': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(Teklel Hafouli, film.performance.character, m.01064ngt)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]',\n",
       "   'context': 'm.01064ngt',\n",
       "   'score': 0.5,\n",
       "   'parent': 2,\n",
       "   'topic_entity': ['m.01064ngt'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(Teklel Hafouli, film.performance.character, m.01064ngt)</paragraph>Unknown Entity[Partially Relevant]'},\n",
       "  '8': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.actor.film, m.0gz5dr6);(Ron Howard, film.actor.film, m.06z_4g2);(Ron Howard, film.actor.film, m.0gz5dg6);(Ron Howard, film.actor.film, m.0gz5dgj);(Ron Howard, film.actor.film, m.0gz5dqr)</paragraph>Unknown Entity[Partially Relevant]',\n",
       "   'pred': '[Continue to Retrieve Evidence]<paragraph>film.actor.film;film.performance.actor;film.film.starring;film.performance.film;type.type.instance</paragraph>film.actor.film[Fully Relevant]film.performance.actor[Partially Relevant]film.film.starring[Partially Relevant][Retrieve Entity]',\n",
       "   'score': 0.5,\n",
       "   'parent': 3,\n",
       "   'topic_entity': ['m.0cg88x1'],\n",
       "   'context': 'film.actor.film[Fully Relevant]film.performance.actor[Partially Relevant]film.film.starring[Partially Relevant]',\n",
       "   'processed_pred': '[Continue to Retrieve Evidence]<paragraph>film.actor.film;film.performance.actor;film.film.starring;film.performance.film;type.type.instance</paragraph>film.actor.film[Fully Relevant]film.performance.actor[Partially Relevant]film.film.starring[Partially Relevant]'},\n",
       "  '9': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.actor.film, m.0gz5dr6);(Ron Howard, film.actor.film, m.06z_4g2);(Ron Howard, film.actor.film, m.0gz5dg6);(Ron Howard, film.actor.film, m.0gz5dgj);(Ron Howard, film.actor.film, m.0gz5dqr)</paragraph>Unknown Entity[Partially Relevant]',\n",
       "   'pred': '[Continue to Retrieve Evidence]<paragraph>type.object.type</paragraph>Unknown-Entity[Relevant]film.performance.actor[Relevant]film.film.starring[Relevant][Retrieve Entity]',\n",
       "   'score': 0.5,\n",
       "   'parent': 3,\n",
       "   'topic_entity': ['m.0cg88x1'],\n",
       "   'context': 'Unknown-Entity[Relevant]film.performance.actor[Relevant]film.film.starring[Relevant]',\n",
       "   'processed_pred': '[Continue to Retrieve Evidence]<paragraph>type.object.type</paragraph>Unknown-Entity[Relevant]film.performance.actor[Relevant]film.film.starring[Relevant]'},\n",
       "  '10': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gly_fg);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0crsy3m);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.011rjztp);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.010dn879);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gz5wf0)</paragraph>Unknown Entity[Partially Relevant]',\n",
       "   'pred': '[Continue to Retrieve Evidence]<paragraph>film.film.personal_appearances;film.person_or_entity_appearing_in_film.films;film.personal_film_appearance.film;film.personal_film_appearance.person;type.type.instance</paragraph>film.personal_film_appearance.film[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.film.personal_appearances[Partially Relevant][Retrieve Entity]',\n",
       "   'score': 0.5,\n",
       "   'parent': 5,\n",
       "   'topic_entity': ['m.0gz5jnz'],\n",
       "   'context': 'film.personal_film_appearance.film[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.film.personal_appearances[Partially Relevant]',\n",
       "   'processed_pred': '[Continue to Retrieve Evidence]<paragraph>film.film.personal_appearances;film.person_or_entity_appearing_in_film.films;film.personal_film_appearance.film;film.personal_film_appearance.person;type.type.instance</paragraph>film.personal_film_appearance.film[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.film.personal_appearances[Partially Relevant]'},\n",
       "  '11': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gly_fg);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0crsy3m);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.011rjztp);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.010dn879);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gz5wf0)</paragraph>Unknown Entity[Partially Relevant]',\n",
       "   'pred': '[Continue to Retrieve Evidence]<paragraph>type.object.type</paragraph>Unknown-Entity[Unrelevant][Continue to Retrieve Evidence]<paragraph>film.performance.actor;film.performance.character;film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.film</paragraph>film.performance.character[Fully Relevant]film.performance.actor[Fully Relevant]film.film_character.portrayed_in_films[Partially Relevant][Retrieve Entity]',\n",
       "   'score': 0.5,\n",
       "   'parent': 5,\n",
       "   'topic_entity': ['m.0gz5jnz'],\n",
       "   'context': 'Unknown-Entity[Unrelevant][Continue to Retrieve Evidence]<paragraph>film.performance.actor;film.performance.character;film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.film</paragraph>film.performance.character[Fully Relevant]film.performance.actor[Fully Relevant]film.film_character.portrayed_in_films[Partially Relevant]',\n",
       "   'processed_pred': '[Continue to Retrieve Evidence]<paragraph>type.object.type</paragraph>Unknown-Entity[Unrelevant][Continue to Retrieve Evidence]<paragraph>film.performance.actor;film.performance.character;film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.film</paragraph>film.performance.character[Fully Relevant]film.performance.actor[Fully Relevant]film.film_character.portrayed_in_films[Partially Relevant]'},\n",
       "  '12': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.actor.film, m.0gz5dr6);(Ron Howard, film.actor.film, m.06z_4g2);(Ron Howard, film.actor.film, m.0gz5dg6);(Ron Howard, film.actor.film, m.0gz5dgj);(Ron Howard, film.actor.film, m.0gz5dqr)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>film.actor.film;film.performance.actor;film.film.starring;film.performance.film;type.type.instance</paragraph>film.actor.film[Fully Relevant]film.performance.actor[Partially Relevant]film.film.starring[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(m.0cg88x1, film.actor.film, Ron Howard)</paragraph>Ron Howard[Partially Relevant]m.0cg88x1[Unrelevant][Continue to Retrieve Evidence]',\n",
       "   'context': 'Ron Howard',\n",
       "   'score': 0.25,\n",
       "   'parent': 8,\n",
       "   'topic_entity': ['m.0g2lq'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(m.0cg88x1, film.actor.film, Ron Howard)</paragraph>Ron Howard[Partially Relevant]m.0cg88x1[Unrelevant]'},\n",
       "  '13': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.actor.film, m.0gz5dr6);(Ron Howard, film.actor.film, m.06z_4g2);(Ron Howard, film.actor.film, m.0gz5dg6);(Ron Howard, film.actor.film, m.0gz5dgj);(Ron Howard, film.actor.film, m.0gz5dqr)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>film.actor.film;film.performance.actor;film.film.starring;film.performance.film;type.type.instance</paragraph>film.actor.film[Fully Relevant]film.performance.actor[Partially Relevant]film.film.starring[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(m.0cg88x1, film.performance.actor, Ron Howard)</paragraph>Ron Howard[Partially Relevant]m.0cg88x1[Unrelevant][Continue to Retrieve Evidence]',\n",
       "   'context': 'Ron Howard',\n",
       "   'score': 0.25,\n",
       "   'parent': 8,\n",
       "   'topic_entity': ['m.0g2lq'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(m.0cg88x1, film.performance.actor, Ron Howard)</paragraph>Ron Howard[Partially Relevant]m.0cg88x1[Unrelevant]'},\n",
       "  '14': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.dubbing_performance.actor;film.film.directed_by;film.actor.film;film.performance.actor;film.film.produced_by</paragraph>film.directed_by[Fully Relevant]film.actor.film[Fully Relevant]film.film.produced_by[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.actor.film, m.0gz5dr6);(Ron Howard, film.actor.film, m.06z_4g2);(Ron Howard, film.actor.film, m.0gz5dg6);(Ron Howard, film.actor.film, m.0gz5dgj);(Ron Howard, film.actor.film, m.0gz5dqr)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>film.actor.film;film.performance.actor;film.film.starring;film.performance.film;type.type.instance</paragraph>film.actor.film[Fully Relevant]film.performance.actor[Partially Relevant]film.film.starring[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(m.0cg88x1, film.film.starring, The Independent)</paragraph>The Independent[Fully Relevant][No Retrieval]Answer: The Independent<|eot_id|>',\n",
       "   'context': '',\n",
       "   'score': 50.0,\n",
       "   'parent': 8,\n",
       "   'topic_entity': ['m.0cg88x1'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(m.0cg88x1, film.film.starring, The Independent)</paragraph>The Independent[Fully Relevant][No Retrieval]Answer: The Independent<|eot_id|>'},\n",
       "  '15': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gly_fg);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0crsy3m);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.011rjztp);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.010dn879);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gz5wf0)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>film.film.personal_appearances;film.person_or_entity_appearing_in_film.films;film.personal_film_appearance.film;film.personal_film_appearance.person;type.type.instance</paragraph>film.personal_film_appearance.film[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.film.personal_appearances[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(m.0gz5jnz, film.personal_film_appearance.film, Untitled Jamie Foxx Documentary)</paragraph>Untitled Jamie Foxx Documentary[Partially Relevant][No Retrieval]Answer: Untitled Jamie Foxx Documentary<|eot_id|>',\n",
       "   'context': '',\n",
       "   'score': 50.0,\n",
       "   'parent': 10,\n",
       "   'topic_entity': ['m.0gz5jnz'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(m.0gz5jnz, film.personal_film_appearance.film, Untitled Jamie Foxx Documentary)</paragraph>Untitled Jamie Foxx Documentary[Partially Relevant][No Retrieval]Answer: Untitled Jamie Foxx Documentary<|eot_id|>'},\n",
       "  '16': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gly_fg);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0crsy3m);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.011rjztp);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.010dn879);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gz5wf0)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>film.film.personal_appearances;film.person_or_entity_appearing_in_film.films;film.personal_film_appearance.film;film.personal_film_appearance.person;type.type.instance</paragraph>film.personal_film_appearance.film[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.film.personal_appearances[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(m.0gz5jnz, film.person_or_entity_appearing_in_film.films, Ron Howard)</paragraph>Ron Howard[Partially Relevant]m.0gz5jnz[Unrelevant][Continue to Retrieve Evidence]',\n",
       "   'context': 'Ron Howard',\n",
       "   'score': 0.25,\n",
       "   'parent': 10,\n",
       "   'topic_entity': ['m.0g2lq'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(m.0gz5jnz, film.person_or_entity_appearing_in_film.films, Ron Howard)</paragraph>Ron Howard[Partially Relevant]m.0gz5jnz[Unrelevant]'},\n",
       "  '17': {'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat movie with the character Teklel Hafouli did Ron Howard do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>[New Retrieval]<paragraph>film.film_character.portrayed_in_films;film.person_or_entity_appearing_in_film.films;film.performance.character</paragraph>film.film_character.portrayed_in_films[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.performance.character[Partially Relevant][Retrieve Entity]<paragraph>(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gly_fg);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0crsy3m);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.011rjztp);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.010dn879);(Ron Howard, film.person_or_entity_appearing_in_film.films, m.0gz5wf0)</paragraph>Unknown Entity[Partially Relevant][Continue to Retrieve Evidence]<paragraph>film.film.personal_appearances;film.person_or_entity_appearing_in_film.films;film.personal_film_appearance.film;film.personal_film_appearance.person;type.type.instance</paragraph>film.personal_film_appearance.film[Fully Relevant]film.person_or_entity_appearing_in_film.films[Partially Relevant]film.film.personal_appearances[Partially Relevant]',\n",
       "   'pred': '[Retrieve Entity]<paragraph>(m.0gz5jnz, film.film.personal_appearances, Untitled Jamie Foxx Documentary)</paragraph>Untitled Jamie Foxx Documentary[Partially Relevant][No Retrieval]Answer: Untitled Jamie Foxx Documentary<|eot_id|>',\n",
       "   'context': '',\n",
       "   'score': 50.0,\n",
       "   'parent': 10,\n",
       "   'topic_entity': ['m.0gz5jnz'],\n",
       "   'processed_pred': '[Retrieve Entity]<paragraph>(m.0gz5jnz, film.film.personal_appearances, Untitled Jamie Foxx Documentary)</paragraph>Untitled Jamie Foxx Documentary[Partially Relevant][No Retrieval]Answer: Untitled Jamie Foxx Documentary<|eot_id|>'}}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwq_result[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m.0gwnx7m': 'm.0gwnx7m',\n",
       " 'm.09kkm44': 'm.09kkm44',\n",
       " 'm.0y4q1x7': 'm.0y4q1x7',\n",
       " 'm.0ysr8tn': 'm.0ysr8tn',\n",
       " 'm.0znq0tb': 'm.0znq0tb'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_another_entity('m.0dl567', 'film.actor.film')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
